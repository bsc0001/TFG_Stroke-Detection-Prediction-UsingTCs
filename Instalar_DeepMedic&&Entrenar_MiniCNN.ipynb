{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepMedic_Install&TinyCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsc0001/TFG_Stroke-Detection-Prediction-UsingTCs/blob/master/DeepMedic_Install%26TinyCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wza59n3GfQ9Z",
        "colab_type": "text"
      },
      "source": [
        "##Instalar y ejecutar el software y modelo de Deepmedic para la creación de una Red Neuronal Convolucional (CNN), cuyo entrenamiento permita la posterior segmentación de escáneres biomédicos en 3D.\n",
        "\n",
        "**Autor**: Bárbara Sainz Crespo\n",
        "*Ingeniería Informática, Escuela Politécnica Superior, Universidad de Burgos*.\n",
        "\n",
        "**Fecha**: 2019/05/09\n",
        "\n",
        "**Descripción**: Instalación del software, así como ciertos requerimientos, para ejecutar el modelo Deepmedic, que permite el acceso a *Deep Learning* para la segmentación de estructuras o regiones de interés (ROIs) en escáneres biomédicos en 3 dimensiones.\n",
        "Se ejecuta el software para crear una Red Neuronal Convolucional (CNN) 3D, que sea entrenada para detectar y segmentar estructuras, aportando sus correspondientes etiquetas de verdad (según un experto), sabiendo que el sistema procesa imágenes con formato NIfTI.\n",
        "La primera ejecución es simplemente para asegurarse de que el sistema es funcional, después se prueba el software con una pequeña muestra de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT6-MZkpOjPr",
        "colab_type": "code",
        "outputId": "87aff3e1-6bbb-4e06-8509-1cb43fe19be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Cloning Deepmedic repository.\n",
        "!git clone https://github.com/Kamnitsask/deepmedic/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deepmedic'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/158)   \u001b[K\rremote: Counting objects:   1% (2/158)   \u001b[K\rremote: Counting objects:   2% (4/158)   \u001b[K\rremote: Counting objects:   3% (5/158)   \u001b[K\rremote: Counting objects:   4% (7/158)   \u001b[K\rremote: Counting objects:   5% (8/158)   \u001b[K\rremote: Counting objects:   6% (10/158)   \u001b[K\rremote: Counting objects:   7% (12/158)   \u001b[K\rremote: Counting objects:   8% (13/158)   \u001b[K\rremote: Counting objects:   9% (15/158)   \u001b[K\rremote: Counting objects:  10% (16/158)   \u001b[K\rremote: Counting objects:  11% (18/158)   \u001b[K\rremote: Counting objects:  12% (19/158)   \u001b[K\rremote: Counting objects:  13% (21/158)   \u001b[K\rremote: Counting objects:  14% (23/158)   \u001b[K\rremote: Counting objects:  15% (24/158)   \u001b[K\rremote: Counting objects:  16% (26/158)   \u001b[K\rremote: Counting objects:  17% (27/158)   \rremote: Counting objects:  18% (29/158)   \u001b[K\rremote: Counting objects:  19% (31/158)   \u001b[K\rremote: Counting objects:  20% (32/158)   \u001b[K\rremote: Counting objects:  21% (34/158)   \u001b[K\rremote: Counting objects:  22% (35/158)   \u001b[K\rremote: Counting objects:  23% (37/158)   \u001b[K\rremote: Counting objects:  24% (38/158)   \u001b[K\rremote: Counting objects:  25% (40/158)   \u001b[K\rremote: Counting objects:  26% (42/158)   \u001b[K\rremote: Counting objects:  27% (43/158)   \u001b[K\rremote: Counting objects:  28% (45/158)   \u001b[K\rremote: Counting objects:  29% (46/158)   \u001b[K\rremote: Counting objects:  30% (48/158)   \u001b[K\rremote: Counting objects:  31% (49/158)   \u001b[K\rremote: Counting objects:  32% (51/158)   \u001b[K\rremote: Counting objects:  33% (53/158)   \u001b[K\rremote: Counting objects:  34% (54/158)   \u001b[K\rremote: Counting objects:  35% (56/158)   \u001b[K\rremote: Counting objects:  36% (57/158)   \u001b[K\rremote: Counting objects:  37% (59/158)   \u001b[K\rremote: Counting objects:  38% (61/158)   \u001b[K\rremote: Counting objects:  39% (62/158)   \u001b[K\rremote: Counting objects:  40% (64/158)   \u001b[K\rremote: Counting objects:  41% (65/158)   \u001b[K\rremote: Counting objects:  42% (67/158)   \u001b[K\rremote: Counting objects:  43% (68/158)   \u001b[K\rremote: Counting objects:  44% (70/158)   \u001b[K\rremote: Counting objects:  45% (72/158)   \u001b[K\rremote: Counting objects:  46% (73/158)   \u001b[K\rremote: Counting objects:  47% (75/158)   \u001b[K\rremote: Counting objects:  48% (76/158)   \rremote: Counting objects:  49% (78/158)   \u001b[K\rremote: Counting objects:  50% (79/158)   \u001b[K\rremote: Counting objects:  51% (81/158)   \u001b[K\rremote: Counting objects:  52% (83/158)   \u001b[K\rremote: Counting objects:  53% (84/158)   \u001b[K\rremote: Counting objects:  54% (86/158)   \u001b[K\rremote: Counting objects:  55% (87/158)   \u001b[K\rremote: Counting objects:  56% (89/158)   \u001b[K\rremote: Counting objects:  57% (91/158)   \u001b[K\rremote: Counting objects:  58% (92/158)   \u001b[K\rremote: Counting objects:  59% (94/158)   \u001b[K\rremote: Counting objects:  60% (95/158)   \u001b[K\rremote: Counting objects:  61% (97/158)   \u001b[K\rremote: Counting objects:  62% (98/158)   \u001b[K\rremote: Counting objects:  63% (100/158)   \u001b[K\rremote: Counting objects:  64% (102/158)   \u001b[K\rremote: Counting objects:  65% (103/158)   \u001b[K\rremote: Counting objects:  66% (105/158)   \u001b[K\rremote: Counting objects:  67% (106/158)   \u001b[K\rremote: Counting objects:  68% (108/158)   \u001b[K\rremote: Counting objects:  69% (110/158)   \u001b[K\rremote: Counting objects:  70% (111/158)   \u001b[K\rremote: Counting objects:  71% (113/158)   \u001b[K\rremote: Counting objects:  72% (114/158)   \u001b[K\rremote: Counting objects:  73% (116/158)   \u001b[K\rremote: Counting objects:  74% (117/158)   \u001b[K\rremote: Counting objects:  75% (119/158)   \u001b[K\rremote: Counting objects:  76% (121/158)   \u001b[K\rremote: Counting objects:  77% (122/158)   \u001b[K\rremote: Counting objects:  78% (124/158)   \u001b[K\rremote: Counting objects:  79% (125/158)   \u001b[K\rremote: Counting objects:  80% (127/158)   \u001b[K\rremote: Counting objects:  81% (128/158)   \u001b[K\rremote: Counting objects:  82% (130/158)   \u001b[K\rremote: Counting objects:  83% (132/158)   \u001b[K\rremote: Counting objects:  84% (133/158)   \u001b[K\rremote: Counting objects:  85% (135/158)   \u001b[K\rremote: Counting objects:  86% (136/158)   \u001b[K\rremote: Counting objects:  87% (138/158)   \u001b[K\rremote: Counting objects:  88% (140/158)   \u001b[K\rremote: Counting objects:  89% (141/158)   \u001b[K\rremote: Counting objects:  90% (143/158)   \u001b[K\rremote: Counting objects:  91% (144/158)   \u001b[K\rremote: Counting objects:  92% (146/158)   \u001b[K\rremote: Counting objects:  93% (147/158)   \u001b[K\rremote: Counting objects:  94% (149/158)   \u001b[K\rremote: Counting objects:  95% (151/158)   \u001b[K\rremote: Counting objects:  96% (152/158)   \u001b[K\rremote: Counting objects:  97% (154/158)   \u001b[K\rremote: Counting objects:  98% (155/158)   \u001b[K\rremote: Counting objects:  99% (157/158)   \u001b[K\rremote: Counting objects: 100% (158/158)   \u001b[K\rremote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 2248 (delta 100), reused 118 (delta 77), pack-reused 2090\u001b[K\n",
            "Receiving objects: 100% (2248/2248), 40.11 MiB | 39.53 MiB/s, done.\n",
            "Resolving deltas: 100% (1474/1474), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrjDhT5gOpf6",
        "colab_type": "code",
        "outputId": "0820889e-7862-4bcb-ed77-5c4adc592ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# Installing updated version of tensorflow, the Deep Learning library for back end.\n",
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.0.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRtvQNumPlPt",
        "colab_type": "code",
        "outputId": "195fbb5f-4670-4500-c64c-cdfcda051877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Going into cloned directory to install Deepmedic and its requirements: NiBabel as the library used for loading NIFTI files, Numpy as a general purpose array-processing package.\n",
        "%cd deepmedic\n",
        "%pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepmedic\n",
            "Processing /content/deepmedic\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from deepmedic==0.7.3) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from deepmedic==0.7.3) (1.16.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from deepmedic==0.7.3) (1.12.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel->deepmedic==0.7.3) (0.98)\n",
            "Building wheels for collected packages: deepmedic\n",
            "  Building wheel for deepmedic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zjuw0yfx/wheels/5c/48/3f/0cc1c161bcb8cde29573d06bea152a4efba3316a6451f5d506\n",
            "Successfully built deepmedic\n",
            "Installing collected packages: deepmedic\n",
            "Successfully installed deepmedic-0.7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMGzqHfBTOOn",
        "colab_type": "code",
        "outputId": "f20a45f2-940b-4bca-8fd9-90c124f7be7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Checking everything is installed.\n",
        "! ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COPYRIGHT.md  documentation  MANIFEST.in\t      setup.cfg\n",
            "deepmedic     examples\t     plotTrainingProgress.py  setup.py\n",
            "deepMedicRun  LICENSE.txt    README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z__WqI_-nm7_",
        "colab_type": "text"
      },
      "source": [
        "If we only intend to install and try the software with a very small sample data, small networks can be run on the CPU, so we can already move forward to do so.\n",
        "\n",
        "However, it is important to comment that 3D CNNs of considerable size require processing on the GPU, which means at this point installation of Nvidia’s CUDA would be needed, a version compatible with the GPU drivers. TensorFlow would need to be able to find CUDA’s compiler (nvcc) in the environment’s path, and it dynamically links to c ublas.so libraries, which would have to be visible in the environments. So prior to running DeepMedic on the GPU, the paths to the folders containing these files in your environment's variables must be added manually.\n",
        "\n",
        "Note: In this particular case, even if we are willing to use GPU, CUDA should already be all set here, and also when attempting to run it with the GPU option \"-dev cuda\", if TensorFlow does not find correct versions for CUDA, it would just fall back to the CPU version by default, which would not be an issue as we are testing a small network, so we can skip this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWoUORdKqSca",
        "colab_type": "text"
      },
      "source": [
        "Moving forward, we run the software´s command line interface, deepMedicRun, with the help option to confirm installation was successful and to see the available actions for the creation, training and testing of CNN models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol3nEal-QinT",
        "colab_type": "code",
        "outputId": "510e6ca9-8981-404b-df30-f04cba61e17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# Running the model with the help option to check it is working as explained previously.\n",
        "!./deepMedicRun -h"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: DeepMedic [-h] [-model MODEL_CFG] [-train TRAIN_CFG] [-test TEST_CFG]\n",
            "                 [-load SAVED_MODEL] [-dev DEVICE] [-resetopt]\n",
            "\n",
            "This software allows creation and supervised training of 3D, multi-scale CNN models for segmentation of structures in biomedical NIFTI volumes.\n",
            "The project is hosted at: https://github.com/Kamnitsask/deepmedic \n",
            "See the documentation for details on its use.\n",
            "This software accompanies the research presented in:\n",
            "Kamnitsas et al, \"Efficient Multi-Scale 3D CNN with Fully Connected CRF for Accurate Brain Lesion Segmentation\", Biomedical Image Analysis, 2016.\n",
            "We hope our work aids you in your endeavours.\n",
            "For questions and feedback contact: konstantinos.kamnitsas12@ic.ac.uk\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help         show this help message and exit\n",
            "  -model MODEL_CFG   Specify the architecture of the model to be used, by providing a config file [MODEL_CFG].\n",
            "  -train TRAIN_CFG   Train a model with training parameters given by specifying config file [TRAINING_CFG].\n",
            "                     This option must follow a [-model MODEL_CFG] option, so that architecture of the to-train model is specified.\n",
            "                     Additionally, an existing checkpoint of the model can be specified in the [TRAIN_CFG] file or by the additional option [-load], to continue training it.\n",
            "  -test TEST_CFG     Test with an existing model. The testing session's parameters should be given in config file [TEST_CFG].\n",
            "                     This option must follow a [-model MODEL_CFG] option, so that architecture of the model is specified.\n",
            "                     Existing pretrained model can be specified in the given [TEST_CFG] file or by the additional option [-load].\n",
            "                     This option cannot be used in combination with [-model] or [-train].\n",
            "  -load SAVED_MODEL  The path to a saved existing checkpoint with learnt weights of the model, to train or test with.\n",
            "                     This option must follow a [-train] or [-test] option.\n",
            "                     If given, this option will override any \"model\" parameters given in the [TRAIN_CFG] or [TEST_CFG] files.\n",
            "  -dev DEVICE        Specify the device to run the process on. Values: [cpu] or [cuda] (default = cpu).\n",
            "                     In the case of multiple GPUs, specify a particular GPU device with a number, in the format: -dev cuda0 \n",
            "                     NOTE: For GPU processing, CUDA libraries must be first added in your environment's PATH and LD_LIBRARY_PATH. See accompanying documentation.\n",
            "  -resetopt          Use optionally with a [-train] command. Does not take an argument.\n",
            "                     Usage: ./deepMedicRun -model /path/to/model/config -train /path/to/train/config -resetopt ...etc...\n",
            "                     Resets the model's optimization state before starting the training session (eg number of epochs already trained, current learning rate etc).\n",
            "                     IMPORTANT: Trainable parameters are NOT reinitialized! \n",
            "                     Useful to begin a secondary training session with new learning-rate schedule, in order to fine-tune a previously trained model (Doc., Sec. 3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PR3LkozxuVH",
        "colab_type": "text"
      },
      "source": [
        "All previuolsly listed actions require a large number of configuration parameters, which are read from configuration files in the examples/configFiles folder. Particularly, examples/configFiles/tinyCnn/ includes the configuration of a small network, to be trained within minutes on a CPU, while examples/configFiles/deepMedic/ provides full configuration of the DeepMedic model. These configuration files are pre-set to point to accompanying nifti files (.nii input files to the networks in these examples) found in examples/dataForExamples/. Note: these data are modified versions of images from the Brain Tumor Segmentation challenge (BRATS 2015)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0lRR0Xq4Ffx",
        "colab_type": "text"
      },
      "source": [
        "The next command parses the given model-configuration file to define the architecture and creates the corresponding CNN model. Then it parses the training-config that specifies metaparameters for the training scheme.\n",
        "\n",
        "The process creates the folder ./examples/output/ to save all output. Also, all output of the process is logged for later reference, found at examples/output/logs/trainSessionWithValidTiny.txt.\n",
        "The model is trained for two epochs, and after each one the trained model is saved at examples/output/saved_models/trainSessionWithValidTiny. Tensorflow saves the model in form of checkpoint files. Finally, after each epoch, the model segmentates the validation images and its results (.nii files) appear in examples/output/predictions/trainSessionWithValidTiny/predictions/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TrpzohEQsuW",
        "colab_type": "code",
        "outputId": "cbfb939a-ce0b-4d41-8863-de1823657ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20267
        }
      },
      "source": [
        "# Training a simple model to make sure everything works correctly.\n",
        "!./deepMedicRun -model ./examples/configFiles/tinyCnn/model/modelConfig.cfg -train examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg -dev cuda0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given configuration file:  /content/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg\n",
            "Given configuration file:  /content/deepmedic/examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg\n",
            "Creating necessary folders for training session...\n",
            "\t>>Created main output folder:  /content/deepmedic/examples/output\n",
            "\t>>Created folder for logs:  /content/deepmedic/examples/output/logs/\n",
            "\t>>Created folder to save cnn-models as they get trained:  /content/deepmedic/examples/output/saved_models/\n",
            "\t>>Created folder to save session's cnn-models as they get trained:  /content/deepmedic/examples/output/saved_models//trainSessionWithValidTiny/\n",
            "\t>>Created folder for predictions:  /content/deepmedic/examples/output/predictions\n",
            "\t>>Created folder for session:  /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny\n",
            "\t>>Created folder for segmentations and probability maps:  /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/\n",
            "\t>>Created folder for features:  /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features/\n",
            "=============================== logger created =======================================\n",
            "\n",
            "======================== Starting new session ============================\n",
            "Command line arguments given: \n",
            "Namespace(device='cuda0', model_cfg='./examples/configFiles/tinyCnn/model/modelConfig.cfg', reset_trainer=False, saved_model=None, test_cfg=None, train_cfg='examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg')\n",
            "2019-05-24 17:48:05.434374: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-05-24 17:48:05.697942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-24 17:48:05.698664: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x16c0f20 executing computations on platform CUDA. Devices:\n",
            "2019-05-24 17:48:05.698725: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-24 17:48:05.702340: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-24 17:48:05.702726: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x16c0dc0 executing computations on platform Host. Devices:\n",
            "2019-05-24 17:48:05.702774: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-24 17:48:05.703195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-24 17:48:05.703244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-24 17:48:05.707022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-24 17:48:05.707056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-24 17:48:05.707070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-24 17:48:05.707303: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-24 17:48:05.707351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Available devices to Tensorflow:\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 9459830863451238130\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 17266899788967912173\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 17609034362057945780\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14892338381\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 13598669901445703097\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n",
            "CONFIG: The configuration file for the [model] given is: /content/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg\n",
            "=============================================================\n",
            "========== PARAMETERS FOR MAKING THE ARCHITECTURE ===========\n",
            "=============================================================\n",
            "CNN model's name = tinyCnn\n",
            "~~~~~~~~~~~~~~~~~~Model parameters~~~~~~~~~~~~~~~~\n",
            "Number of Classes (including background) = 5\n",
            "~~Normal Pathway~~\n",
            "Number of Input Channels = 2\n",
            "Number of Layers = 3\n",
            "Number of Feature Maps per layer = [4, 5, 6]\n",
            "Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
            "Receptive Field = [7, 7, 7]\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Lower Rank layers will be made of rank = []\n",
            "~~Subsampled Pathway~~\n",
            "Use subsampled Pathway = True\n",
            "Number of subsampled pathways that will be built = 1\n",
            "Number of Layers (per sub-pathway) = [3]\n",
            "Number of Feature Maps per layer (per sub-pathway) = [[4, 5, 6]]\n",
            "Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
            "Receptive Field = [7, 7, 7]\n",
            "Subsampling Factor per dimension (per sub-pathway) = [[3, 3, 3]]\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Lower Rank layers will be made of rank = []\n",
            "~~Fully Connected Pathway~~\n",
            "Number of additional FC layers (Excluding the Classif. Layer) = 0\n",
            "Number of Feature Maps in the additional FC layers = []\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Dimensions of Kernels in the 1st FC layer (Classif. layer if no hidden FCs used) = [1, 1, 1]\n",
            "~~Size Of Image Segments~~\n",
            "Size of Segments for Training = [25, 25, 25]\n",
            "Size of Segments for Validation = [7, 7, 7]\n",
            "Size of Segments for Testing = [45, 45, 45]\n",
            "~~Dropout Rates~~\n",
            "Drop.R. for each layer in Normal Pathway = []\n",
            "Drop.R. for each layer in Subsampled Pathway = []\n",
            "Drop.R. for each layer in FC Pathway (additional FC layers + Classific.Layer at end) = [0.5]\n",
            "~~Weight Initialization~~\n",
            "Initialization method and params for the conv kernel weights = ['fanIn', 2]\n",
            "~~Activation Function~~\n",
            "Activation function to use = prelu\n",
            "~~Batch Normalization~~\n",
            "Apply BN straight on pathways' inputs (eg straight on segments) = [False, False, True]\n",
            "Batch Normalization uses a rolling average for inference, over this many batches = 60\n",
            "========== Done with printing session's parameters ==========\n",
            "=============================================================\n",
            "CONFIG: The configuration file for the [session] was loaded from: /content/deepmedic/examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg\n",
            "\n",
            "=============   NEW TRAINING SESSION     ==============\n",
            "\n",
            "\n",
            "=============================================================\n",
            "========= PARAMETERS FOR THIS TRAINING SESSION ==============\n",
            "=============================================================\n",
            "Session's name = trainSessionWithValidTiny\n",
            "Model will be loaded from save = None\n",
            "~~Output~~\n",
            "Main output folder = /content/deepmedic/examples/output\n",
            "Path and filename to save trained models = /content/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny\n",
            "~~~~~~~~~~~~~~~~~~Generic Information~~~~~~~~~~~~~~~~\n",
            "Number of Cases for Training = 2\n",
            "Number of Cases for Validation = 2\n",
            "~~~~~~~~~~~~~~~~~~Training parameters~~~~~~~~~~~~~~~~\n",
            "Filepaths to Channels of the Training Cases = [['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/T1c_subtrMeanDivStd.nii.gz'], ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/T1c_subtrMeanDivStd.nii.gz']]\n",
            "Filepaths to Ground-Truth labels of the Training Cases = ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/OTMultiClass.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/OTMultiClass.nii.gz']\n",
            "~~ Sampling (train) ~~\n",
            "Region-Of-Interest Masks provided = True\n",
            "Filepaths to ROI Masks of the Training Cases = ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/brainmask.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/brainmask.nii.gz']\n",
            "Type of Sampling = Per-Class (3)\n",
            "Sampling Categories = ['Class-0', 'Class-1', 'Class-2', 'Class-3', 'Class-4']\n",
            "Percent of Samples to extract per Sampling Category = [0.2 0.2 0.2 0.2 0.2]\n",
            "Provided Weight-Maps, pointing where to focus sampling for each category (if False, samples will be extracted based on GT and ROI) = False\n",
            "Paths to weight-Maps for sampling of each category = None\n",
            "~~Training Cycle~~\n",
            "Number of Epochs = 2\n",
            "Number of Subepochs per epoch = 2\n",
            "Number of cases to load per Subepoch (for extracting the samples for this subepoch) = 50\n",
            "Number of Segments loaded per subepoch for Training = 1000. NOTE: This number of segments divided by the batch-size defines the number of optimization-iterations that will be performed every subepoch!\n",
            "Batch size (train) = 10\n",
            "Number of parallel processes for sampling = 0\n",
            "~~Learning Rate Schedule~~\n",
            "Type of schedule = poly\n",
            "[Predef] Predefined schedule of epochs when the LR will be lowered = None\n",
            "[Predef] When decreasing Learning Rate, divide LR by = 2.0\n",
            "[Poly] Initial epochs to wait before lowering LR = 0.6666666666666666\n",
            "[Poly] Final epoch for the schedule = 2\n",
            "[Auto] Initial epochs to wait before lowering LR = 5\n",
            "[Auto] When decreasing Learning Rate, divide LR by = 2.0\n",
            "[Auto] Minimum increase in validation accuracy (0. to 1.) that resets the waiting counter = 0.0\n",
            "[Expon] (Deprecated) parameters = {'epochs_wait_before_decr': 0.6666666666666666, 'final_ep_for_sch': 2, 'lr_to_reach_at_last_ep': 0.00390625, 'mom_to_reach_at_last_ep': 0.9}\n",
            "~~Data Augmentation During Training~~\n",
            "Mu and std for shift and scale of histograms = {'shift': {'mu': 0.0, 'std': 0.05}, 'scale': {'mu': 1.0, 'std': 0.01}}\n",
            "Probabilities of reflecting each axis = (0.5, 0.0, 0.0)\n",
            "Probabilities of rotating planes 0/90/180/270 degrees = {'xy': {'0': 0.8, '90': 0.1, '180': 0.0, '270': 0.1}, 'yz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}, 'xz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}}\n",
            "~~~~~~~~~~~~~~~~~~Validation parameters~~~~~~~~~~~~~~~~\n",
            "Perform Validation on Samples throughout training? = True\n",
            "Perform Full Inference on validation cases every few epochs? = True\n",
            "Filepaths to Channels of the Validation Cases (Req for either of the above) = [['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/T1c_subtrMeanDivStd.nii.gz'], ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/T1c_subtrMeanDivStd.nii.gz']]\n",
            "Provided Ground-Truth for Validation = True. NOTE: Required for Val on samples. Not Req for Full-Inference, but DSC will be reported if provided.\n",
            "Filepaths to Ground-Truth labels of the Validation Cases = ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/OTMultiClass.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/OTMultiClass.nii.gz']\n",
            "Provided ROI masks for Validation = True. NOTE: Validation-sampling and Full-Inference will be limited within this mask if provided. If not provided, Negative Validation samples will be extracted from whole volume, except if advanced-sampling is enabled, and the user provided separate weight-maps for sampling.\n",
            "Filepaths to ROI masks for Validation Cases = ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/brainmask.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/brainmask.nii.gz']\n",
            "~~~~~~~Validation on Samples throughout Training~~~~~~~\n",
            "Number of Segments loaded per subepoch for Validation = 5000\n",
            "Batch size (val on samples) = 50\n",
            "~~ Sampling (val) ~~\n",
            "Type of Sampling = Uniform (1)\n",
            "Sampling Categories = ['Uniform']\n",
            "Percent of Samples to extract per Sampling Category = [1.0]\n",
            "Provided Weight-Maps, pointing where to focus sampling for each category (if False, samples will be extracted based on GT and ROI) = False\n",
            "Paths to weight-maps for sampling of each category = None\n",
            "~~~~~Validation with Full Inference on Validation Cases~~~~~\n",
            "Perform Full-Inference on Val. cases every that many epochs = 1\n",
            "Batch size (val on whole volumes) = 10\n",
            "~~Predictions (segmentations and prob maps on val. cases)~~\n",
            "Save Segmentations = True\n",
            "Save Probability Maps for each class = [True, True, True, True, True]\n",
            "Filepaths to save results per case = ['/content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0003_1.nii.gz', '/content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0004_1.nii.gz']\n",
            "Suffixes with which to save segmentations and probability maps = {'segm': 'Segm', 'prob': 'ProbMapClass'}\n",
            "~~Feature Maps~~\n",
            "Save Feature Maps = False\n",
            "Save FMs in a 4D-image = False\n",
            "Min/Max Indices of FMs to visualise per pathway-type and per layer = None\n",
            "Filepaths to save FMs per case = ['/content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0003_1.nii.gz', '/content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0004_1.nii.gz']\n",
            "~~Optimization~~\n",
            "Initial Learning rate = 0.001\n",
            "Optimizer to use: SGD(0), Adam(1), RmsProp(2) = 2\n",
            "Parameters for Adam: b1= placeholder, b2=placeholder, e= placeholder\n",
            "Parameters for RmsProp: rho= 0.9, e= 0.0001\n",
            "Momentum Type: Classic (0) or Nesterov (1) = 1\n",
            "Momentum Non-Normalized (0) or Normalized (1) = 1\n",
            "Momentum Value = 0.6\n",
            "~~Costs~~\n",
            "Loss functions and their weights = {'xentr': 1.0, 'iou': None, 'dsc': None}\n",
            "Reweight samples in cost on a per-class basis = {'type': None, 'prms': None, 'schedule': [0, 2]}\n",
            "L1 Regularization term = 1e-06\n",
            "L2 Regularization term = 0.0001\n",
            "~~Freeze Weights of Certain Layers~~\n",
            "Indices of layers from each type of pathway that will be kept fixed (first layer is 0):\n",
            "Normal pathway's layers to freeze = []\n",
            "Subsampled pathway's layers to freeze = []\n",
            "FC pathway's layers to freeze = []\n",
            "~~~~~~~~~~~~~~~~~~Other Generic Parameters~~~~~~~~~~~~~~~~\n",
            "Check whether input data has correct format (can slow down process) = True\n",
            "~~Pre Processing~~\n",
            "Pad Input Images = True\n",
            "========== Done with printing session's parameters ==========\n",
            "=============================================================\n",
            "\n",
            "=======================================================\n",
            "\n",
            "=========== Making the CNN graph... ===============\n",
            "...Building the CNN model...\n",
            "[Pathway_NORMAL] is being built...\n",
            "\t[Pathway_NORMAL]: Input's Shape: (Train) [None, 2, 25, 25, 25], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 45, 45, 45]\n",
            "\t[Conv.Layer_0], Filter Shape: [4, 2, 3, 3, 3]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 2, 25, 25, 25], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 45, 45, 45]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\t[Conv.Layer_1], Filter Shape: [5, 4, 3, 3, 3]\n",
            "\t[Conv.Layer_1], Input's Shape: (Train) [None, 4, 23, 23, 23], (Val) [None, 4, 5, 5, 5], (Test) [None, 4, 43, 43, 43]\n",
            "\t[Conv.Layer_2], Filter Shape: [6, 5, 3, 3, 3]\n",
            "\t[Conv.Layer_2], Input's Shape: (Train) [None, 5, 21, 21, 21], (Val) [None, 5, 3, 3, 3], (Test) [None, 5, 41, 41, 41]\n",
            "\t[Pathway_NORMAL]: Output's Shape: (Train) [None, 6, 19, 19, 19], (Val) [None, 6, 1, 1, 1], (Test) [None, 6, 39, 39, 39]\n",
            "[Pathway_NORMAL] done.\n",
            "[Pathway_SUBSAMPLED[3, 3, 3]] is being built...\n",
            "\t[Pathway_SUBSAMPLED[3, 3, 3]]: Input's Shape: (Train) [None, 2, 13, 13, 13], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 19, 19, 19]\n",
            "\t[Conv.Layer_0], Filter Shape: [4, 2, 3, 3, 3]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 2, 13, 13, 13], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 19, 19, 19]\n",
            "\t[Conv.Layer_1], Filter Shape: [5, 4, 3, 3, 3]\n",
            "\t[Conv.Layer_1], Input's Shape: (Train) [None, 4, 11, 11, 11], (Val) [None, 4, 5, 5, 5], (Test) [None, 4, 17, 17, 17]\n",
            "\t[Conv.Layer_2], Filter Shape: [6, 5, 3, 3, 3]\n",
            "\t[Conv.Layer_2], Input's Shape: (Train) [None, 5, 9, 9, 9], (Val) [None, 5, 3, 3, 3], (Test) [None, 5, 15, 15, 15]\n",
            "\t[Pathway_SUBSAMPLED[3, 3, 3]]: Output's Shape: (Train) [None, 6, 7, 7, 7], (Val) [None, 6, 1, 1, 1], (Test) [None, 6, 13, 13, 13]\n",
            "[Pathway_SUBSAMPLED[3, 3, 3]] done.\n",
            "DEBUG: Shape of the kernel of the first FC layer is : [1, 1, 1]\n",
            "DEBUG: Input to the FC Pathway will be padded by that many voxels per dimension: [0, 0, 0]\n",
            "[Pathway_FC] is being built...\n",
            "\t[Pathway_FC]: Input's Shape: (Train) [None, 12, 19, 19, 19], (Val) [None, 12, 1, 1, 1], (Test) [None, 12, 39, 39, 39]\n",
            "\t[Conv.Layer_0], Filter Shape: [5, 12, 1, 1, 1]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 12, 19, 19, 19], (Val) [None, 12, 1, 1, 1], (Test) [None, 12, 39, 39, 39]\n",
            "\t[Pathway_FC]: Output's Shape: (Train) [None, 5, 19, 19, 19], (Val) [None, 5, 1, 1, 1], (Test) [None, 5, 39, 39, 39]\n",
            "[Pathway_FC] done.\n",
            "Adding the final Softmax Target layer...\n",
            "Finished building the CNN's model.\n",
            "=========== Building Trainer ===========\n",
            "\n",
            "Building Trainer.\n",
            "COST: Using cross entropy with weight: 1.0\n",
            "...Initializing state of the optimizer...\n",
            "=========== Compiling the Training Function ===========\n",
            "=======================================================\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "...Building the training function...\n",
            "...Collecting ops and feeds for training...\n",
            "Done.\n",
            "=========== Compiling the Validation Function =========\n",
            "...Building the validation function...\n",
            "...Collecting ops and feeds for validation...\n",
            "Done.\n",
            "=========== Compiling the Testing Function ============\n",
            "...Building the function for testing and visualisation of FMs...\n",
            "...Collecting ops and feeds for testing...\n",
            "Done.\n",
            "2019-05-24 17:48:08.604301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-24 17:48:08.604370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-24 17:48:08.604386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-24 17:48:08.604396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-24 17:48:08.604687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "=========== Initializing network and trainer variables  ===============\n",
            "All variables were initialized.\n",
            "Saving the initial model at:/content/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny.initial.2019-05-24.17.48.23.753012\n",
            "\n",
            "=======================================================\n",
            "============== Training the CNN model =================\n",
            "=======================================================\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~\t Starting new Epoch! Epoch #0/2 \t~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "***************************************************************************************\n",
            "*******\t\t Starting new Subepoch: #0/2 \t\t********\n",
            "***************************************************************************************\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [VALIDATION].\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:\n",
            "[SAMPLER-VAL|PID:230] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-VAL|PID:230] Shuffled indices of subjects that were randomly chosen: [0, 1]\n",
            "[SAMPLER-VAL|PID:230] Will sample from [2] subjects for next Validation...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 0 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 1 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[SAMPLER-VAL|PID:230] TIMING: Sampling for next [Validation] lasted: 3.9 secs.\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Finished sampling for next [Validation] :=:=:=:=:=:=:\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [TRAINING].\n",
            "-V-V-V-V-V- Now Validating for this subepoch before commencing the training iterations... -V-V-V-V-V-\n",
            "[VALIDATION] Validated on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:\n",
            "[SAMPLER-TR|PID:230] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-TR|PID:230] Shuffled indices of subjects that were randomly chosen: [0, 1]\n",
            "[SAMPLER-TR|PID:230] Will sample from [2] subjects for next Training...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 0 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "2019-05-24 17:48:31.176312: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "[VALIDATION] Validated on 20/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 40/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 60/100 of the batches for this subepoch...\n",
            "[JOB:0|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 1 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[VALIDATION] Validated on 80/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Overall:\t mean accuracy:   \t0.0982\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 491/5000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-0:\t mean accuracy:   \t0.1646\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 823/5000\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-0:\t mean sensitivity:\t0.9715\t=> TruePos/RealPos = 478/492\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-0:\t mean precision:\t0.1030\t=> TruePos/(TruePos+FalsePos) = 478/4641\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-0:\t mean specificity:\t0.0765\t=> TrueNeg/RealNeg = 345/4508\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-0:\t mean Dice:       \t0.1862\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-1:\t mean accuracy:   \t0.9510\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4755/5000\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-1:\t mean sensitivity:\t0.0556\t=> TruePos/RealPos = 2/36\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-1:\t mean precision:\t0.0094\t=> TruePos/(TruePos+FalsePos) = 2/213\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-1:\t mean specificity:\t0.9575\t=> TrueNeg/RealNeg = 4753/4964\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-1:\t mean Dice:       \t0.0161\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-2:\t mean accuracy:   \t0.7284\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 3642/5000\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-2:\t mean sensitivity:\t0.1825\t=> TruePos/RealPos = 52/285\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-2:\t mean precision:\t0.0442\t=> TruePos/(TruePos+FalsePos) = 52/1177\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-2:\t mean specificity:\t0.7614\t=> TrueNeg/RealNeg = 3590/4715\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-2:\t mean Dice:       \t0.0711\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-3:\t mean accuracy:   \t0.4214\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 2107/5000\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-3:\t mean sensitivity:\t0.9286\t=> TruePos/RealPos = 91/98\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-3:\t mean precision:\t0.0306\t=> TruePos/(TruePos+FalsePos) = 91/2977\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-3:\t mean specificity:\t0.4113\t=> TrueNeg/RealNeg = 2016/4902\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-3:\t mean Dice:       \t0.0592\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-4:\t mean accuracy:   \t0.9310\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4655/5000\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-4:\t mean sensitivity:\t0.0137\t=> TruePos/RealPos = 1/73\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-4:\t mean precision:\t0.0036\t=> TruePos/(TruePos+FalsePos) = 1/274\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-4:\t mean specificity:\t0.9446\t=> TrueNeg/RealNeg = 4654/4927\n",
            "VALIDATION: Epoch #0, Subepoch #0, Class-4:\t mean Dice:       \t0.0058\n",
            "TIMING: Validation on batches of this subepoch #0 lasted: 5.0 secs.\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[SAMPLER-TR|PID:230] TIMING: Sampling for next [Training] lasted: 8.0 secs.\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Finished sampling for next [Training] :=:=:=:=:=:=:\n",
            "[MAIN|PID:230] MULTIPROC: Before Training in subepoch #0, submitting sampling job for next [VALIDATION].\n",
            "-T-T-T-T-T- Now Training for this subepoch... This may take a few minutes... -T-T-T-T-T-\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:\n",
            "[TRAINING] Trained on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-VAL|PID:230] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-VAL|PID:230] Shuffled indices of subjects that were randomly chosen: [0, 1]\n",
            "[SAMPLER-VAL|PID:230] Will sample from [2] subjects for next Validation...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 0 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 1 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[TRAINING] Trained on 20/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 40/100 of the batches for this subepoch...\n",
            "[JOB:1|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[SAMPLER-VAL|PID:230] TIMING: Sampling for next [Validation] lasted: 4.7 secs.\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Finished sampling for next [Validation] :=:=:=:=:=:=:\n",
            "[TRAINING] Trained on 60/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 80/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Overall:\t mean accuracy:   \t0.4066\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 2788613/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Overall:\t mean cost:      \t1.43637\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-0:\t mean accuracy:   \t0.6983\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4789952/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-0:\t mean sensitivity:\t0.7599\t=> TruePos/RealPos = 3244827/4270297\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-0:\t mean precision:\t0.7567\t=> TruePos/(TruePos+FalsePos) = 3244827/4288405\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-0:\t mean specificity:\t0.5969\t=> TrueNeg/RealNeg = 1545125/2588703\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-0:\t mean Dice:       \t0.7583\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-1:\t mean accuracy:   \t0.7673\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5263146/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-1:\t mean sensitivity:\t0.2219\t=> TruePos/RealPos = 285530/1286820\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-1:\t mean precision:\t0.3244\t=> TruePos/(TruePos+FalsePos) = 285530/880094\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-1:\t mean specificity:\t0.8933\t=> TrueNeg/RealNeg = 4977616/5572180\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-1:\t mean Dice:       \t0.2635\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-2:\t mean accuracy:   \t0.7565\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5188875/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-2:\t mean sensitivity:\t0.2903\t=> TruePos/RealPos = 389364/1341186\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-2:\t mean precision:\t0.3515\t=> TruePos/(TruePos+FalsePos) = 389364/1107667\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-2:\t mean specificity:\t0.8698\t=> TrueNeg/RealNeg = 4799511/5517814\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-2:\t mean Dice:       \t0.3180\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-3:\t mean accuracy:   \t0.7963\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5461842/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-3:\t mean sensitivity:\t0.2101\t=> TruePos/RealPos = 102945/490022\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-3:\t mean precision:\t0.0925\t=> TruePos/(TruePos+FalsePos) = 102945/1113026\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-3:\t mean specificity:\t0.8414\t=> TrueNeg/RealNeg = 5358897/6368978\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-3:\t mean Dice:       \t0.1284\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-4:\t mean accuracy:   \t0.7946\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5450411/6859000\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-4:\t mean sensitivity:\t0.4041\t=> TruePos/RealPos = 465649/1152269\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-4:\t mean precision:\t0.3921\t=> TruePos/(TruePos+FalsePos) = 465649/1187618\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-4:\t mean specificity:\t0.8735\t=> TrueNeg/RealNeg = 4984762/5706731\n",
            "TRAINING: Epoch #0, Subepoch #0, Class-4:\t mean Dice:       \t0.3980\n",
            "TIMING: Training on batches of this subepoch #0 lasted: 6.4 secs.\n",
            "***************************************************************************************\n",
            "*******\t\t Starting new Subepoch: #1/2 \t\t********\n",
            "***************************************************************************************\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #1, submitting sampling job for next [TRAINING].\n",
            "-V-V-V-V-V- Now Validating for this subepoch before commencing the training iterations... -V-V-V-V-V-\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:\n",
            "[VALIDATION] Validated on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-TR|PID:230] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-TR|PID:230] Shuffled indices of subjects that were randomly chosen: [1, 0]\n",
            "[SAMPLER-TR|PID:230] Will sample from [2] subjects for next Training...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 1 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[VALIDATION] Validated on 20/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 40/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 60/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 80/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Overall:\t mean accuracy:   \t0.9010\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4505/5000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-0:\t mean accuracy:   \t0.9440\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4720/5000\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-0:\t mean sensitivity:\t0.9726\t=> TruePos/RealPos = 497/511\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-0:\t mean precision:\t0.6514\t=> TruePos/(TruePos+FalsePos) = 497/763\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-0:\t mean specificity:\t0.9407\t=> TrueNeg/RealNeg = 4223/4489\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-0:\t mean Dice:       \t0.7802\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-1:\t mean accuracy:   \t0.9808\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4904/5000\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-1:\t mean sensitivity:\t0.4762\t=> TruePos/RealPos = 10/21\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-1:\t mean precision:\t0.1053\t=> TruePos/(TruePos+FalsePos) = 10/95\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-1:\t mean specificity:\t0.9829\t=> TrueNeg/RealNeg = 4894/4979\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-1:\t mean Dice:       \t0.1724\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-2:\t mean accuracy:   \t0.9410\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4705/5000\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-2:\t mean sensitivity:\t0.7165\t=> TruePos/RealPos = 230/321\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-2:\t mean precision:\t0.5300\t=> TruePos/(TruePos+FalsePos) = 230/434\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-2:\t mean specificity:\t0.9564\t=> TrueNeg/RealNeg = 4475/4679\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-2:\t mean Dice:       \t0.6093\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-3:\t mean accuracy:   \t0.9776\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4888/5000\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-3:\t mean sensitivity:\t0.0291\t=> TruePos/RealPos = 3/103\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-3:\t mean precision:\t0.2000\t=> TruePos/(TruePos+FalsePos) = 3/15\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-3:\t mean specificity:\t0.9975\t=> TrueNeg/RealNeg = 4885/4897\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-3:\t mean Dice:       \t0.0508\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-4:\t mean accuracy:   \t0.9586\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4793/5000\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-4:\t mean sensitivity:\t0.5909\t=> TruePos/RealPos = 39/66\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-4:\t mean precision:\t0.1781\t=> TruePos/(TruePos+FalsePos) = 39/219\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-4:\t mean specificity:\t0.9635\t=> TrueNeg/RealNeg = 4754/4934\n",
            "VALIDATION: Epoch #0, Subepoch #1, Class-4:\t mean Dice:       \t0.2737\n",
            "TIMING: Validation on batches of this subepoch #1 lasted: 0.8 secs.\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 0 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[SAMPLER-TR|PID:230] TIMING: Sampling for next [Training] lasted: 6.8 secs.\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Finished sampling for next [Training] :=:=:=:=:=:=:\n",
            "-T-T-T-T-T- Now Training for this subepoch... This may take a few minutes... -T-T-T-T-T-\n",
            "[TRAINING] Trained on 1/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 20/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 40/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 60/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 80/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Overall:\t mean accuracy:   \t0.5648\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 3874147/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Overall:\t mean cost:      \t1.22625\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-0:\t mean accuracy:   \t0.7588\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5204892/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-0:\t mean sensitivity:\t0.6819\t=> TruePos/RealPos = 2863984/4200041\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-0:\t mean precision:\t0.9000\t=> TruePos/(TruePos+FalsePos) = 2863984/3182035\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-0:\t mean specificity:\t0.8804\t=> TrueNeg/RealNeg = 2340908/2658959\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-0:\t mean Dice:       \t0.7759\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-1:\t mean accuracy:   \t0.8141\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5583586/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-1:\t mean sensitivity:\t0.3710\t=> TruePos/RealPos = 457824/1234154\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-1:\t mean precision:\t0.4784\t=> TruePos/(TruePos+FalsePos) = 457824/956908\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-1:\t mean specificity:\t0.9113\t=> TrueNeg/RealNeg = 5125762/5624846\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-1:\t mean Dice:       \t0.4179\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-2:\t mean accuracy:   \t0.7903\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5420460/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-2:\t mean sensitivity:\t0.3342\t=> TruePos/RealPos = 441465/1320937\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-2:\t mean precision:\t0.4412\t=> TruePos/(TruePos+FalsePos) = 441465/1000533\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-2:\t mean specificity:\t0.8990\t=> TrueNeg/RealNeg = 4978995/5538063\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-2:\t mean Dice:       \t0.3803\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-3:\t mean accuracy:   \t0.9052\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6208635/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-3:\t mean sensitivity:\t0.0516\t=> TruePos/RealPos = 26036/504991\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-3:\t mean precision:\t0.1319\t=> TruePos/(TruePos+FalsePos) = 26036/197446\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-3:\t mean specificity:\t0.9730\t=> TrueNeg/RealNeg = 6182599/6354009\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-3:\t mean Dice:       \t0.0741\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-4:\t mean accuracy:   \t0.8613\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5907721/6859000\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-4:\t mean sensitivity:\t0.5333\t=> TruePos/RealPos = 607914/1139959\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-4:\t mean precision:\t0.5918\t=> TruePos/(TruePos+FalsePos) = 607914/1027148\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-4:\t mean specificity:\t0.9267\t=> TrueNeg/RealNeg = 5299807/5719041\n",
            "TRAINING: Epoch #0, Subepoch #1, Class-4:\t mean Dice:       \t0.5610\n",
            "TIMING: Training on batches of this subepoch #1 lasted: 2.7 secs.\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~ Epoch #0 finished. Reporting Accuracy over whole epoch. ~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Overall:\t mean accuracy of epoch:\t0.4996\t=> Correctly-Classified-Voxels/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Overall:\t mean accuracy of each subepoch:\t[ 0.0982 0.9010 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Class-0:\t mean accuracy of epoch:\t0.5543\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Class-0:\t mean sensitivity of epoch:\t0.9721\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #0, Class-0:\t mean precision of epoch:\t0.3772\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #0, Class-0:\t mean specificity of epoch:\t0.5086\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #0, Class-0:\t mean Dice of epoch:    \t0.4832\n",
            "VALIDATION: Epoch #0, Class-0:\t mean accuracy of each subepoch:\t[ 0.1646 0.9440 ]\n",
            "VALIDATION: Epoch #0, Class-0:\t mean sensitivity of each subepoch:\t[ 0.9715 0.9726 ]\n",
            "VALIDATION: Epoch #0, Class-0:\t mean precision of each subepoch:\t[ 0.1030 0.6514 ]\n",
            "VALIDATION: Epoch #0, Class-0:\t mean specificity of each subepoch:\t[ 0.0765 0.9407 ]\n",
            "VALIDATION: Epoch #0, Class-0:\t mean Dice of each subepoch:    \t[ 0.1862 0.7802 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Class-1:\t mean accuracy of epoch:\t0.9659\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Class-1:\t mean sensitivity of epoch:\t0.2659\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #0, Class-1:\t mean precision of epoch:\t0.0573\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #0, Class-1:\t mean specificity of epoch:\t0.9702\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #0, Class-1:\t mean Dice of epoch:    \t0.0942\n",
            "VALIDATION: Epoch #0, Class-1:\t mean accuracy of each subepoch:\t[ 0.9510 0.9808 ]\n",
            "VALIDATION: Epoch #0, Class-1:\t mean sensitivity of each subepoch:\t[ 0.0556 0.4762 ]\n",
            "VALIDATION: Epoch #0, Class-1:\t mean precision of each subepoch:\t[ 0.0094 0.1053 ]\n",
            "VALIDATION: Epoch #0, Class-1:\t mean specificity of each subepoch:\t[ 0.9575 0.9829 ]\n",
            "VALIDATION: Epoch #0, Class-1:\t mean Dice of each subepoch:    \t[ 0.0161 0.1724 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Class-2:\t mean accuracy of epoch:\t0.8347\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Class-2:\t mean sensitivity of epoch:\t0.4495\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #0, Class-2:\t mean precision of epoch:\t0.2871\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #0, Class-2:\t mean specificity of epoch:\t0.8589\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #0, Class-2:\t mean Dice of epoch:    \t0.3402\n",
            "VALIDATION: Epoch #0, Class-2:\t mean accuracy of each subepoch:\t[ 0.7284 0.9410 ]\n",
            "VALIDATION: Epoch #0, Class-2:\t mean sensitivity of each subepoch:\t[ 0.1825 0.7165 ]\n",
            "VALIDATION: Epoch #0, Class-2:\t mean precision of each subepoch:\t[ 0.0442 0.5300 ]\n",
            "VALIDATION: Epoch #0, Class-2:\t mean specificity of each subepoch:\t[ 0.7614 0.9564 ]\n",
            "VALIDATION: Epoch #0, Class-2:\t mean Dice of each subepoch:    \t[ 0.0711 0.6093 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Class-3:\t mean accuracy of epoch:\t0.6995\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Class-3:\t mean sensitivity of epoch:\t0.4788\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #0, Class-3:\t mean precision of epoch:\t0.1153\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #0, Class-3:\t mean specificity of epoch:\t0.7044\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #0, Class-3:\t mean Dice of epoch:    \t0.0550\n",
            "VALIDATION: Epoch #0, Class-3:\t mean accuracy of each subepoch:\t[ 0.4214 0.9776 ]\n",
            "VALIDATION: Epoch #0, Class-3:\t mean sensitivity of each subepoch:\t[ 0.9286 0.0291 ]\n",
            "VALIDATION: Epoch #0, Class-3:\t mean precision of each subepoch:\t[ 0.0306 0.2000 ]\n",
            "VALIDATION: Epoch #0, Class-3:\t mean specificity of each subepoch:\t[ 0.4113 0.9975 ]\n",
            "VALIDATION: Epoch #0, Class-3:\t mean Dice of each subepoch:    \t[ 0.0592 0.0508 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #0, Class-4:\t mean accuracy of epoch:\t0.9448\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #0, Class-4:\t mean sensitivity of epoch:\t0.3023\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #0, Class-4:\t mean precision of epoch:\t0.0909\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #0, Class-4:\t mean specificity of epoch:\t0.9541\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #0, Class-4:\t mean Dice of epoch:    \t0.1397\n",
            "VALIDATION: Epoch #0, Class-4:\t mean accuracy of each subepoch:\t[ 0.9310 0.9586 ]\n",
            "VALIDATION: Epoch #0, Class-4:\t mean sensitivity of each subepoch:\t[ 0.0137 0.5909 ]\n",
            "VALIDATION: Epoch #0, Class-4:\t mean precision of each subepoch:\t[ 0.0036 0.1781 ]\n",
            "VALIDATION: Epoch #0, Class-4:\t mean specificity of each subepoch:\t[ 0.9446 0.9635 ]\n",
            "VALIDATION: Epoch #0, Class-4:\t mean Dice of each subepoch:    \t[ 0.0058 0.2737 ]\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Overall:\t mean accuracy of epoch:\t0.4857\t=> Correctly-Classified-Voxels/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Overall:\t mean cost of epoch:    \t1.33131\n",
            "TRAINING: Epoch #0, Overall:\t mean accuracy of each subepoch:\t[ 0.4066 0.5648 ]\n",
            "TRAINING: Epoch #0, Overall:\t mean cost of each subepoch:    \t[ 1.43637 1.22625 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Class-0:\t mean accuracy of epoch:\t0.7286\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Class-0:\t mean sensitivity of epoch:\t0.7209\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #0, Class-0:\t mean precision of epoch:\t0.8283\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #0, Class-0:\t mean specificity of epoch:\t0.7386\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #0, Class-0:\t mean Dice of epoch:    \t0.7671\n",
            "TRAINING: Epoch #0, Class-0:\t mean accuracy of each subepoch:\t[ 0.6983 0.7588 ]\n",
            "TRAINING: Epoch #0, Class-0:\t mean sensitivity of each subepoch:\t[ 0.7599 0.6819 ]\n",
            "TRAINING: Epoch #0, Class-0:\t mean precision of each subepoch:\t[ 0.7567 0.9000 ]\n",
            "TRAINING: Epoch #0, Class-0:\t mean specificity of each subepoch:\t[ 0.5969 0.8804 ]\n",
            "TRAINING: Epoch #0, Class-0:\t mean Dice of each subepoch:    \t[ 0.7583 0.7759 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Class-1:\t mean accuracy of epoch:\t0.7907\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Class-1:\t mean sensitivity of epoch:\t0.2964\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #0, Class-1:\t mean precision of epoch:\t0.4014\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #0, Class-1:\t mean specificity of epoch:\t0.9023\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #0, Class-1:\t mean Dice of epoch:    \t0.3407\n",
            "TRAINING: Epoch #0, Class-1:\t mean accuracy of each subepoch:\t[ 0.7673 0.8141 ]\n",
            "TRAINING: Epoch #0, Class-1:\t mean sensitivity of each subepoch:\t[ 0.2219 0.3710 ]\n",
            "TRAINING: Epoch #0, Class-1:\t mean precision of each subepoch:\t[ 0.3244 0.4784 ]\n",
            "TRAINING: Epoch #0, Class-1:\t mean specificity of each subepoch:\t[ 0.8933 0.9113 ]\n",
            "TRAINING: Epoch #0, Class-1:\t mean Dice of each subepoch:    \t[ 0.2635 0.4179 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Class-2:\t mean accuracy of epoch:\t0.7734\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Class-2:\t mean sensitivity of epoch:\t0.3123\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #0, Class-2:\t mean precision of epoch:\t0.3964\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #0, Class-2:\t mean specificity of epoch:\t0.8844\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #0, Class-2:\t mean Dice of epoch:    \t0.3492\n",
            "TRAINING: Epoch #0, Class-2:\t mean accuracy of each subepoch:\t[ 0.7565 0.7903 ]\n",
            "TRAINING: Epoch #0, Class-2:\t mean sensitivity of each subepoch:\t[ 0.2903 0.3342 ]\n",
            "TRAINING: Epoch #0, Class-2:\t mean precision of each subepoch:\t[ 0.3515 0.4412 ]\n",
            "TRAINING: Epoch #0, Class-2:\t mean specificity of each subepoch:\t[ 0.8698 0.8990 ]\n",
            "TRAINING: Epoch #0, Class-2:\t mean Dice of each subepoch:    \t[ 0.3180 0.3803 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Class-3:\t mean accuracy of epoch:\t0.8507\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Class-3:\t mean sensitivity of epoch:\t0.1308\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #0, Class-3:\t mean precision of epoch:\t0.1122\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #0, Class-3:\t mean specificity of epoch:\t0.9072\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #0, Class-3:\t mean Dice of epoch:    \t0.1013\n",
            "TRAINING: Epoch #0, Class-3:\t mean accuracy of each subepoch:\t[ 0.7963 0.9052 ]\n",
            "TRAINING: Epoch #0, Class-3:\t mean sensitivity of each subepoch:\t[ 0.2101 0.0516 ]\n",
            "TRAINING: Epoch #0, Class-3:\t mean precision of each subepoch:\t[ 0.0925 0.1319 ]\n",
            "TRAINING: Epoch #0, Class-3:\t mean specificity of each subepoch:\t[ 0.8414 0.9730 ]\n",
            "TRAINING: Epoch #0, Class-3:\t mean Dice of each subepoch:    \t[ 0.1284 0.0741 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #0, Class-4:\t mean accuracy of epoch:\t0.8280\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #0, Class-4:\t mean sensitivity of epoch:\t0.4687\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #0, Class-4:\t mean precision of epoch:\t0.4920\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #0, Class-4:\t mean specificity of epoch:\t0.9001\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #0, Class-4:\t mean Dice of epoch:    \t0.4795\n",
            "TRAINING: Epoch #0, Class-4:\t mean accuracy of each subepoch:\t[ 0.7946 0.8613 ]\n",
            "TRAINING: Epoch #0, Class-4:\t mean sensitivity of each subepoch:\t[ 0.4041 0.5333 ]\n",
            "TRAINING: Epoch #0, Class-4:\t mean precision of each subepoch:\t[ 0.3921 0.5918 ]\n",
            "TRAINING: Epoch #0, Class-4:\t mean specificity of each subepoch:\t[ 0.8735 0.9267 ]\n",
            "TRAINING: Epoch #0, Class-4:\t mean Dice of each subepoch:    \t[ 0.3980 0.5610 ]\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "Trainer: Current learning rate: 0.00077188946\n",
            "Trainer: Current momentum: 0.6\n",
            "Trainer: Number of epochs the model has been trained: 1\n",
            "SAVING: Epoch #0 finished. Saving CNN model.\n",
            "TIMING: The whole Epoch #0 lasted: 28.3 secs.\n",
            "~~~~~~~~~~~~~~~~~~~~ End of Training Epoch. Model was Saved. ~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "***Starting validation with Full Inference / Segmentation on validation subjects for Epoch #0...***\n",
            "###########################################################################################################\n",
            "############################# Starting full Segmentation of Validation subjects ##########################\n",
            "###########################################################################################################\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #0 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            " WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:90\n",
            "Processed 10/90 segments.\n",
            "Processed 20/90 segments.\n",
            "Processed 30/90 segments.\n",
            "Processed 40/90 segments.\n",
            "Processed 50/90 segments.\n",
            "Processed 60/90 segments.\n",
            "Processed 70/90 segments.\n",
            "Processed 80/90 segments.\n",
            "Processed 90/90 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.08 [ForwardPass:] 0.45 [Total:] 0.55 secs.\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass4.nii.gz\n",
            "+++++++++++++++++++++ Reporting Segmentation Metrics for the subject #0 ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #0 equal: DICE1=[ 0.8380 0.0000 0.7134 0.0000 0.4327 ] DICE2=[ 0.8402 0.0000 0.7134 0.0000 0.4329 ] DICE3=[ 0.8405 0.0000 0.7137 0.0000 0.4329 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #1 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            " WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:80\n",
            "Processed 10/80 segments.\n",
            "Processed 20/80 segments.\n",
            "Processed 30/80 segments.\n",
            "Processed 40/80 segments.\n",
            "Processed 50/80 segments.\n",
            "Processed 60/80 segments.\n",
            "Processed 70/80 segments.\n",
            "Processed 80/80 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.07 [ForwardPass:] 0.24 [Total:] 0.33 secs.\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass4.nii.gz\n",
            "+++++++++++++++++++++ Reporting Segmentation Metrics for the subject #1 ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #1 equal: DICE1=[ 0.8333 0.2430 0.3769 0.0000 0.5310 ] DICE2=[ 0.8352 0.2447 0.3770 0.0000 0.5313 ] DICE3=[ 0.8352 0.2447 0.3770 0.0000 0.5313 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "+++++++++++++++++++++++++++++++ Segmentation of all subjects finished +++++++++++++++++++++++++++++++++++\n",
            "+++++++++++++++++++++ Reporting Average Segmentation Metrics over all subjects ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class average DICE Coefficients over all subjects are: DICE1=[ 0.8357 0.1215 0.5452 0.0000 0.4819 ] DICE2=[ 0.8377 0.1223 0.5452 0.0000 0.4821 ] DICE3=[ 0.8379 0.1223 0.5454 0.0000 0.4821 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "TIMING: Validation process lasted: 13.97 secs.\n",
            "###########################################################################################################\n",
            "############################# Finished full Segmentation of Validation subjects ##########################\n",
            "###########################################################################################################\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~\t Starting new Epoch! Epoch #1/2 \t~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "***************************************************************************************\n",
            "*******\t\t Starting new Subepoch: #0/2 \t\t********\n",
            "***************************************************************************************\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [VALIDATION].\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:\n",
            "[SAMPLER-VAL|PID:230] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-VAL|PID:230] Shuffled indices of subjects that were randomly chosen: [0, 1]\n",
            "[SAMPLER-VAL|PID:230] Will sample from [2] subjects for next Validation...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 0 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 1 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[SAMPLER-VAL|PID:230] TIMING: Sampling for next [Validation] lasted: 3.6 secs.\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Finished sampling for next [Validation] :=:=:=:=:=:=:\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [TRAINING].\n",
            "-V-V-V-V-V- Now Validating for this subepoch before commencing the training iterations... -V-V-V-V-V-\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:\n",
            "[VALIDATION] Validated on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-TR|PID:230] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-TR|PID:230] Shuffled indices of subjects that were randomly chosen: [1, 0]\n",
            "[SAMPLER-TR|PID:230] Will sample from [2] subjects for next Training...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 1 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[VALIDATION] Validated on 20/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 40/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 60/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 80/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Overall:\t mean accuracy:   \t0.9186\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4593/5000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-0:\t mean accuracy:   \t0.9624\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4812/5000\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-0:\t mean sensitivity:\t0.9501\t=> TruePos/RealPos = 476/501\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-0:\t mean precision:\t0.7449\t=> TruePos/(TruePos+FalsePos) = 476/639\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-0:\t mean specificity:\t0.9638\t=> TrueNeg/RealNeg = 4336/4499\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-0:\t mean Dice:       \t0.8351\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-1:\t mean accuracy:   \t0.9630\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4815/5000\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-1:\t mean sensitivity:\t0.9032\t=> TruePos/RealPos = 28/31\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-1:\t mean precision:\t0.1333\t=> TruePos/(TruePos+FalsePos) = 28/210\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-1:\t mean specificity:\t0.9634\t=> TrueNeg/RealNeg = 4787/4969\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-1:\t mean Dice:       \t0.2324\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-2:\t mean accuracy:   \t0.9516\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4758/5000\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-2:\t mean sensitivity:\t0.5852\t=> TruePos/RealPos = 182/311\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-2:\t mean precision:\t0.6169\t=> TruePos/(TruePos+FalsePos) = 182/295\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-2:\t mean specificity:\t0.9759\t=> TrueNeg/RealNeg = 4576/4689\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-2:\t mean Dice:       \t0.6007\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-3:\t mean accuracy:   \t0.9818\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4909/5000\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-3:\t mean sensitivity:\t0.0000\t=> TruePos/RealPos = 0/91\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-3:\t mean precision:\tN/A\t=> TruePos/(TruePos+FalsePos) = 0/0\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-3:\t mean specificity:\t1.0000\t=> TrueNeg/RealNeg = 4909/4909\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-3:\t mean Dice:       \t0.0000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-4:\t mean accuracy:   \t0.9784\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4892/5000\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-4:\t mean sensitivity:\t0.6912\t=> TruePos/RealPos = 47/68\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-4:\t mean precision:\t0.3507\t=> TruePos/(TruePos+FalsePos) = 47/134\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-4:\t mean specificity:\t0.9824\t=> TrueNeg/RealNeg = 4845/4932\n",
            "VALIDATION: Epoch #1, Subepoch #0, Class-4:\t mean Dice:       \t0.4653\n",
            "TIMING: Validation on batches of this subepoch #0 lasted: 0.7 secs.\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 0 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[SAMPLER-TR|PID:230] TIMING: Sampling for next [Training] lasted: 6.7 secs.\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Finished sampling for next [Training] :=:=:=:=:=:=:\n",
            "[MAIN|PID:230] MULTIPROC: Before Training in subepoch #0, submitting sampling job for next [VALIDATION].\n",
            "-T-T-T-T-T- Now Training for this subepoch... This may take a few minutes... -T-T-T-T-T-\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:\n",
            "[TRAINING] Trained on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-VAL|PID:230] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-VAL|PID:230] Shuffled indices of subjects that were randomly chosen: [1, 0]\n",
            "[SAMPLER-VAL|PID:230] Will sample from [2] subjects for next Validation...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 1 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[TRAINING] Trained on 20/100 of the batches for this subepoch...\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[TRAINING] Trained on 40/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 60/100 of the batches for this subepoch...\n",
            "[JOB:0|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 0 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[TRAINING] Trained on 80/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Overall:\t mean accuracy:   \t0.6010\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4122186/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Overall:\t mean cost:      \t1.12044\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-0:\t mean accuracy:   \t0.7604\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5215435/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-0:\t mean sensitivity:\t0.6694\t=> TruePos/RealPos = 2791726/4170297\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-0:\t mean precision:\t0.9133\t=> TruePos/(TruePos+FalsePos) = 2791726/3056720\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-0:\t mean specificity:\t0.9014\t=> TrueNeg/RealNeg = 2423709/2688703\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-0:\t mean Dice:       \t0.7726\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-1:\t mean accuracy:   \t0.8286\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5683191/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-1:\t mean sensitivity:\t0.4603\t=> TruePos/RealPos = 582915/1266436\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-1:\t mean precision:\t0.5421\t=> TruePos/(TruePos+FalsePos) = 582915/1075203\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-1:\t mean specificity:\t0.9120\t=> TrueNeg/RealNeg = 5100276/5592564\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-1:\t mean Dice:       \t0.4979\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-2:\t mean accuracy:   \t0.8115\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5565909/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-2:\t mean sensitivity:\t0.3546\t=> TruePos/RealPos = 437974/1234977\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-2:\t mean precision:\t0.4689\t=> TruePos/(TruePos+FalsePos) = 437974/934062\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-2:\t mean specificity:\t0.9118\t=> TrueNeg/RealNeg = 5127935/5624023\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-2:\t mean Dice:       \t0.4038\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-3:\t mean accuracy:   \t0.9247\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6342464/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-3:\t mean sensitivity:\t0.0131\t=> TruePos/RealPos = 6323/483483\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-3:\t mean precision:\t0.1384\t=> TruePos/(TruePos+FalsePos) = 6323/45699\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-3:\t mean specificity:\t0.9938\t=> TrueNeg/RealNeg = 6336141/6375517\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-3:\t mean Dice:       \t0.0239\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-4:\t mean accuracy:   \t0.8769\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6014373/6859000\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-4:\t mean sensitivity:\t0.5663\t=> TruePos/RealPos = 671265/1185401\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-4:\t mean precision:\t0.6701\t=> TruePos/(TruePos+FalsePos) = 671265/1001756\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-4:\t mean specificity:\t0.9417\t=> TrueNeg/RealNeg = 5343108/5673599\n",
            "TRAINING: Epoch #1, Subepoch #0, Class-4:\t mean Dice:       \t0.6138\n",
            "TIMING: Training on batches of this subepoch #0 lasted: 4.2 secs.\n",
            "***************************************************************************************\n",
            "*******\t\t Starting new Subepoch: #1/2 \t\t********\n",
            "***************************************************************************************\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Uniform: 2500/2500] \n",
            "[SAMPLER-VAL|PID:230] TIMING: Sampling for next [Validation] lasted: 5.1 secs.\n",
            "[SAMPLER-VAL|PID:230] :=:=:=:=:=:=: Finished sampling for next [Validation] :=:=:=:=:=:=:\n",
            "[MAIN|PID:230] MULTIPROC: Before Validation in subepoch #1, submitting sampling job for next [TRAINING].\n",
            "-V-V-V-V-V- Now Validating for this subepoch before commencing the training iterations... -V-V-V-V-V-\n",
            "[VALIDATION] Validated on 1/100 of the batches for this subepoch...\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:\n",
            "[SAMPLER-TR|PID:230] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.\n",
            "[SAMPLER-TR|PID:230] Shuffled indices of subjects that were randomly chosen: [1, 0]\n",
            "[SAMPLER-TR|PID:230] Will sample from [2] subjects for next Training...\n",
            "[JOB:0|PID:230] Load & sample from subject of index (in user's list): 1 (Job #0/2)\n",
            "[JOB:0|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[VALIDATION] Validated on 20/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 40/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 60/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 80/100 of the batches for this subepoch...\n",
            "[VALIDATION] Validated on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Overall:\t mean accuracy:   \t0.9320\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4660/5000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-0:\t mean accuracy:   \t0.9732\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4866/5000\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-0:\t mean sensitivity:\t0.9642\t=> TruePos/RealPos = 485/503\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-0:\t mean precision:\t0.8070\t=> TruePos/(TruePos+FalsePos) = 485/601\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-0:\t mean specificity:\t0.9742\t=> TrueNeg/RealNeg = 4381/4497\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-0:\t mean Dice:       \t0.8786\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-1:\t mean accuracy:   \t0.9720\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4860/5000\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-1:\t mean sensitivity:\t0.8649\t=> TruePos/RealPos = 32/37\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-1:\t mean precision:\t0.1916\t=> TruePos/(TruePos+FalsePos) = 32/167\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-1:\t mean specificity:\t0.9728\t=> TrueNeg/RealNeg = 4828/4963\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-1:\t mean Dice:       \t0.3137\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-2:\t mean accuracy:   \t0.9562\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4781/5000\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-2:\t mean sensitivity:\t0.6549\t=> TruePos/RealPos = 186/284\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-2:\t mean precision:\t0.6059\t=> TruePos/(TruePos+FalsePos) = 186/307\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-2:\t mean specificity:\t0.9743\t=> TrueNeg/RealNeg = 4595/4716\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-2:\t mean Dice:       \t0.6294\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-3:\t mean accuracy:   \t0.9794\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4897/5000\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-3:\t mean sensitivity:\t0.0000\t=> TruePos/RealPos = 0/103\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-3:\t mean precision:\tN/A\t=> TruePos/(TruePos+FalsePos) = 0/0\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-3:\t mean specificity:\t1.0000\t=> TrueNeg/RealNeg = 4897/4897\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-3:\t mean Dice:       \t0.0000\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-4:\t mean accuracy:   \t0.9832\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4916/5000\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-4:\t mean sensitivity:\t0.7722\t=> TruePos/RealPos = 61/79\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-4:\t mean precision:\t0.4803\t=> TruePos/(TruePos+FalsePos) = 61/127\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-4:\t mean specificity:\t0.9866\t=> TrueNeg/RealNeg = 4855/4921\n",
            "VALIDATION: Epoch #1, Subepoch #1, Class-4:\t mean Dice:       \t0.5922\n",
            "TIMING: Validation on batches of this subepoch #1 lasted: 0.8 secs.\n",
            "[JOB:0|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:0|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[JOB:1|PID:230] Load & sample from subject of index (in user's list): 0 (Job #1/2)\n",
            "[JOB:1|PID:230] Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz\n",
            "[JOB:1|PID:230]  WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "[JOB:1|PID:230] Got samples per category: [Class-0: 100/100] [Class-1: 100/100] [Class-2: 100/100] [Class-3: 100/100] [Class-4: 100/100] \n",
            "[SAMPLER-TR|PID:230] TIMING: Sampling for next [Training] lasted: 6.9 secs.\n",
            "[SAMPLER-TR|PID:230] :=:=:=:=:=:=: Finished sampling for next [Training] :=:=:=:=:=:=:\n",
            "-T-T-T-T-T- Now Training for this subepoch... This may take a few minutes... -T-T-T-T-T-\n",
            "[TRAINING] Trained on 1/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 20/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 40/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 60/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 80/100 of the batches for this subepoch...\n",
            "[TRAINING] Trained on 100/100 of the batches for this subepoch...\n",
            "+++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Overall:\t mean accuracy:   \t0.6150\t=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4218366/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Overall:\t mean cost:      \t1.06526\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-0:\t mean accuracy:   \t0.7593\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5208037/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-0:\t mean sensitivity:\t0.6683\t=> TruePos/RealPos = 2782707/4163827\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-0:\t mean precision:\t0.9116\t=> TruePos/(TruePos+FalsePos) = 2782707/3052550\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-0:\t mean specificity:\t0.8999\t=> TrueNeg/RealNeg = 2425330/2695173\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-0:\t mean Dice:       \t0.7712\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-1:\t mean accuracy:   \t0.8400\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5761848/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-1:\t mean sensitivity:\t0.5024\t=> TruePos/RealPos = 634072/1262133\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-1:\t mean precision:\t0.5748\t=> TruePos/(TruePos+FalsePos) = 634072/1103163\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-1:\t mean specificity:\t0.9162\t=> TrueNeg/RealNeg = 5127776/5596867\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-1:\t mean Dice:       \t0.5361\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-2:\t mean accuracy:   \t0.8177\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5608805/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-2:\t mean sensitivity:\t0.3867\t=> TruePos/RealPos = 490968/1269558\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-2:\t mean precision:\t0.5101\t=> TruePos/(TruePos+FalsePos) = 490968/962573\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-2:\t mean specificity:\t0.9156\t=> TrueNeg/RealNeg = 5117837/5589442\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-2:\t mean Dice:       \t0.4399\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-3:\t mean accuracy:   \t0.9270\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6358092/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-3:\t mean sensitivity:\t0.0078\t=> TruePos/RealPos = 3792/485275\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-3:\t mean precision:\t0.1633\t=> TruePos/(TruePos+FalsePos) = 3792/23217\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-3:\t mean specificity:\t0.9970\t=> TrueNeg/RealNeg = 6354300/6373725\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-3:\t mean Dice:       \t0.0149\n",
            "+++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-4:\t mean accuracy:   \t0.8860\t=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6076950/6859000\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-4:\t mean sensitivity:\t0.5791\t=> TruePos/RealPos = 664204/1146861\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-4:\t mean precision:\t0.6893\t=> TruePos/(TruePos+FalsePos) = 664204/963597\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-4:\t mean specificity:\t0.9476\t=> TrueNeg/RealNeg = 5412746/5712139\n",
            "TRAINING: Epoch #1, Subepoch #1, Class-4:\t mean Dice:       \t0.6294\n",
            "TIMING: Training on batches of this subepoch #1 lasted: 3.0 secs.\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~ Epoch #1 finished. Reporting Accuracy over whole epoch. ~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Overall:\t mean accuracy of epoch:\t0.9253\t=> Correctly-Classified-Voxels/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Overall:\t mean accuracy of each subepoch:\t[ 0.9186 0.9320 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Class-0:\t mean accuracy of epoch:\t0.9678\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Class-0:\t mean sensitivity of epoch:\t0.9572\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #1, Class-0:\t mean precision of epoch:\t0.7760\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #1, Class-0:\t mean specificity of epoch:\t0.9690\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #1, Class-0:\t mean Dice of epoch:    \t0.8569\n",
            "VALIDATION: Epoch #1, Class-0:\t mean accuracy of each subepoch:\t[ 0.9624 0.9732 ]\n",
            "VALIDATION: Epoch #1, Class-0:\t mean sensitivity of each subepoch:\t[ 0.9501 0.9642 ]\n",
            "VALIDATION: Epoch #1, Class-0:\t mean precision of each subepoch:\t[ 0.7449 0.8070 ]\n",
            "VALIDATION: Epoch #1, Class-0:\t mean specificity of each subepoch:\t[ 0.9638 0.9742 ]\n",
            "VALIDATION: Epoch #1, Class-0:\t mean Dice of each subepoch:    \t[ 0.8351 0.8786 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Class-1:\t mean accuracy of epoch:\t0.9675\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Class-1:\t mean sensitivity of epoch:\t0.8840\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #1, Class-1:\t mean precision of epoch:\t0.1625\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #1, Class-1:\t mean specificity of epoch:\t0.9681\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #1, Class-1:\t mean Dice of epoch:    \t0.2730\n",
            "VALIDATION: Epoch #1, Class-1:\t mean accuracy of each subepoch:\t[ 0.9630 0.9720 ]\n",
            "VALIDATION: Epoch #1, Class-1:\t mean sensitivity of each subepoch:\t[ 0.9032 0.8649 ]\n",
            "VALIDATION: Epoch #1, Class-1:\t mean precision of each subepoch:\t[ 0.1333 0.1916 ]\n",
            "VALIDATION: Epoch #1, Class-1:\t mean specificity of each subepoch:\t[ 0.9634 0.9728 ]\n",
            "VALIDATION: Epoch #1, Class-1:\t mean Dice of each subepoch:    \t[ 0.2324 0.3137 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Class-2:\t mean accuracy of epoch:\t0.9539\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Class-2:\t mean sensitivity of epoch:\t0.6201\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #1, Class-2:\t mean precision of epoch:\t0.6114\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #1, Class-2:\t mean specificity of epoch:\t0.9751\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #1, Class-2:\t mean Dice of epoch:    \t0.6151\n",
            "VALIDATION: Epoch #1, Class-2:\t mean accuracy of each subepoch:\t[ 0.9516 0.9562 ]\n",
            "VALIDATION: Epoch #1, Class-2:\t mean sensitivity of each subepoch:\t[ 0.5852 0.6549 ]\n",
            "VALIDATION: Epoch #1, Class-2:\t mean precision of each subepoch:\t[ 0.6169 0.6059 ]\n",
            "VALIDATION: Epoch #1, Class-2:\t mean specificity of each subepoch:\t[ 0.9759 0.9743 ]\n",
            "VALIDATION: Epoch #1, Class-2:\t mean Dice of each subepoch:    \t[ 0.6007 0.6294 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Class-3:\t mean accuracy of epoch:\t0.9806\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Class-3:\t mean sensitivity of epoch:\t0.0000\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #1, Class-3:\t mean precision of epoch:\tN/A\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #1, Class-3:\t mean specificity of epoch:\t1.0000\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #1, Class-3:\t mean Dice of epoch:    \t0.0000\n",
            "VALIDATION: Epoch #1, Class-3:\t mean accuracy of each subepoch:\t[ 0.9818 0.9794 ]\n",
            "VALIDATION: Epoch #1, Class-3:\t mean sensitivity of each subepoch:\t[ 0.0000 0.0000 ]\n",
            "VALIDATION: Epoch #1, Class-3:\t mean precision of each subepoch:\t[ N/A N/A ]\n",
            "VALIDATION: Epoch #1, Class-3:\t mean specificity of each subepoch:\t[ 1.0000 1.0000 ]\n",
            "VALIDATION: Epoch #1, Class-3:\t mean Dice of each subepoch:    \t[ 0.0000 0.0000 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "VALIDATION: Epoch #1, Class-4:\t mean accuracy of epoch:\t0.9808\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "VALIDATION: Epoch #1, Class-4:\t mean sensitivity of epoch:\t0.7317\t=> TruePos/RealPos\n",
            "VALIDATION: Epoch #1, Class-4:\t mean precision of epoch:\t0.4155\t=> TruePos/(TruePos+FalsePos)\n",
            "VALIDATION: Epoch #1, Class-4:\t mean specificity of epoch:\t0.9845\t=> TrueNeg/RealNeg\n",
            "VALIDATION: Epoch #1, Class-4:\t mean Dice of epoch:    \t0.5288\n",
            "VALIDATION: Epoch #1, Class-4:\t mean accuracy of each subepoch:\t[ 0.9784 0.9832 ]\n",
            "VALIDATION: Epoch #1, Class-4:\t mean sensitivity of each subepoch:\t[ 0.6912 0.7722 ]\n",
            "VALIDATION: Epoch #1, Class-4:\t mean precision of each subepoch:\t[ 0.3507 0.4803 ]\n",
            "VALIDATION: Epoch #1, Class-4:\t mean specificity of each subepoch:\t[ 0.9824 0.9866 ]\n",
            "VALIDATION: Epoch #1, Class-4:\t mean Dice of each subepoch:    \t[ 0.4653 0.5922 ]\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Overall:\t mean accuracy of epoch:\t0.6080\t=> Correctly-Classified-Voxels/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Overall:\t mean cost of epoch:    \t1.09285\n",
            "TRAINING: Epoch #1, Overall:\t mean accuracy of each subepoch:\t[ 0.6010 0.6150 ]\n",
            "TRAINING: Epoch #1, Overall:\t mean cost of each subepoch:    \t[ 1.12044 1.06526 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Class-0:\t mean accuracy of epoch:\t0.7598\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Class-0:\t mean sensitivity of epoch:\t0.6689\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #1, Class-0:\t mean precision of epoch:\t0.9125\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #1, Class-0:\t mean specificity of epoch:\t0.9007\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #1, Class-0:\t mean Dice of epoch:    \t0.7719\n",
            "TRAINING: Epoch #1, Class-0:\t mean accuracy of each subepoch:\t[ 0.7604 0.7593 ]\n",
            "TRAINING: Epoch #1, Class-0:\t mean sensitivity of each subepoch:\t[ 0.6694 0.6683 ]\n",
            "TRAINING: Epoch #1, Class-0:\t mean precision of each subepoch:\t[ 0.9133 0.9116 ]\n",
            "TRAINING: Epoch #1, Class-0:\t mean specificity of each subepoch:\t[ 0.9014 0.8999 ]\n",
            "TRAINING: Epoch #1, Class-0:\t mean Dice of each subepoch:    \t[ 0.7726 0.7712 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Class-1:\t mean accuracy of epoch:\t0.8343\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Class-1:\t mean sensitivity of epoch:\t0.4813\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #1, Class-1:\t mean precision of epoch:\t0.5585\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #1, Class-1:\t mean specificity of epoch:\t0.9141\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #1, Class-1:\t mean Dice of epoch:    \t0.5170\n",
            "TRAINING: Epoch #1, Class-1:\t mean accuracy of each subepoch:\t[ 0.8286 0.8400 ]\n",
            "TRAINING: Epoch #1, Class-1:\t mean sensitivity of each subepoch:\t[ 0.4603 0.5024 ]\n",
            "TRAINING: Epoch #1, Class-1:\t mean precision of each subepoch:\t[ 0.5421 0.5748 ]\n",
            "TRAINING: Epoch #1, Class-1:\t mean specificity of each subepoch:\t[ 0.9120 0.9162 ]\n",
            "TRAINING: Epoch #1, Class-1:\t mean Dice of each subepoch:    \t[ 0.4979 0.5361 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Class-2:\t mean accuracy of epoch:\t0.8146\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Class-2:\t mean sensitivity of epoch:\t0.3707\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #1, Class-2:\t mean precision of epoch:\t0.4895\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #1, Class-2:\t mean specificity of epoch:\t0.9137\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #1, Class-2:\t mean Dice of epoch:    \t0.4219\n",
            "TRAINING: Epoch #1, Class-2:\t mean accuracy of each subepoch:\t[ 0.8115 0.8177 ]\n",
            "TRAINING: Epoch #1, Class-2:\t mean sensitivity of each subepoch:\t[ 0.3546 0.3867 ]\n",
            "TRAINING: Epoch #1, Class-2:\t mean precision of each subepoch:\t[ 0.4689 0.5101 ]\n",
            "TRAINING: Epoch #1, Class-2:\t mean specificity of each subepoch:\t[ 0.9118 0.9156 ]\n",
            "TRAINING: Epoch #1, Class-2:\t mean Dice of each subepoch:    \t[ 0.4038 0.4399 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Class-3:\t mean accuracy of epoch:\t0.9258\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Class-3:\t mean sensitivity of epoch:\t0.0104\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #1, Class-3:\t mean precision of epoch:\t0.1508\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #1, Class-3:\t mean specificity of epoch:\t0.9954\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #1, Class-3:\t mean Dice of epoch:    \t0.0194\n",
            "TRAINING: Epoch #1, Class-3:\t mean accuracy of each subepoch:\t[ 0.9247 0.9270 ]\n",
            "TRAINING: Epoch #1, Class-3:\t mean sensitivity of each subepoch:\t[ 0.0131 0.0078 ]\n",
            "TRAINING: Epoch #1, Class-3:\t mean precision of each subepoch:\t[ 0.1384 0.1633 ]\n",
            "TRAINING: Epoch #1, Class-3:\t mean specificity of each subepoch:\t[ 0.9938 0.9970 ]\n",
            "TRAINING: Epoch #1, Class-3:\t mean Dice of each subepoch:    \t[ 0.0239 0.0149 ]\n",
            ">>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<\n",
            "TRAINING: Epoch #1, Class-4:\t mean accuracy of epoch:\t0.8814\t=> (TruePos+TrueNeg)/All-Predicted-Voxels\n",
            "TRAINING: Epoch #1, Class-4:\t mean sensitivity of epoch:\t0.5727\t=> TruePos/RealPos\n",
            "TRAINING: Epoch #1, Class-4:\t mean precision of epoch:\t0.6797\t=> TruePos/(TruePos+FalsePos)\n",
            "TRAINING: Epoch #1, Class-4:\t mean specificity of epoch:\t0.9447\t=> TrueNeg/RealNeg\n",
            "TRAINING: Epoch #1, Class-4:\t mean Dice of epoch:    \t0.6216\n",
            "TRAINING: Epoch #1, Class-4:\t mean accuracy of each subepoch:\t[ 0.8769 0.8860 ]\n",
            "TRAINING: Epoch #1, Class-4:\t mean sensitivity of each subepoch:\t[ 0.5663 0.5791 ]\n",
            "TRAINING: Epoch #1, Class-4:\t mean precision of each subepoch:\t[ 0.6701 0.6893 ]\n",
            "TRAINING: Epoch #1, Class-4:\t mean specificity of each subepoch:\t[ 0.9417 0.9476 ]\n",
            "TRAINING: Epoch #1, Class-4:\t mean Dice of each subepoch:    \t[ 0.6138 0.6294 ]\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "Trainer: Current learning rate: 3.1459535e-10\n",
            "Trainer: Current momentum: 0.6\n",
            "Trainer: Number of epochs the model has been trained: 2\n",
            "SAVING: Epoch #1 finished. Saving CNN model.\n",
            "TIMING: The whole Epoch #1 lasted: 25.6 secs.\n",
            "~~~~~~~~~~~~~~~~~~~~ End of Training Epoch. Model was Saved. ~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "***Starting validation with Full Inference / Segmentation on validation subjects for Epoch #1...***\n",
            "###########################################################################################################\n",
            "############################# Starting full Segmentation of Validation subjects ##########################\n",
            "###########################################################################################################\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #0 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz\n",
            " WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:90\n",
            "Processed 10/90 segments.\n",
            "Processed 20/90 segments.\n",
            "Processed 30/90 segments.\n",
            "Processed 40/90 segments.\n",
            "Processed 50/90 segments.\n",
            "Processed 60/90 segments.\n",
            "Processed 70/90 segments.\n",
            "Processed 80/90 segments.\n",
            "Processed 90/90 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.07 [ForwardPass:] 0.18 [Total:] 0.27 secs.\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass4.nii.gz\n",
            "+++++++++++++++++++++ Reporting Segmentation Metrics for the subject #0 ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #0 equal: DICE1=[ 0.8385 0.0000 0.7727 0.0000 0.4819 ] DICE2=[ 0.8434 0.0000 0.7727 0.0000 0.4821 ] DICE3=[ 0.8437 0.0000 0.7730 0.0000 0.4821 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #1 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz\n",
            " WARN: Loaded labels are dtype [float32]. Rounding and casting them to int!\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:80\n",
            "Processed 10/80 segments.\n",
            "Processed 20/80 segments.\n",
            "Processed 30/80 segments.\n",
            "Processed 40/80 segments.\n",
            "Processed 50/80 segments.\n",
            "Processed 60/80 segments.\n",
            "Processed 70/80 segments.\n",
            "Processed 80/80 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.07 [ForwardPass:] 0.23 [Total:] 0.31 secs.\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass4.nii.gz\n",
            "+++++++++++++++++++++ Reporting Segmentation Metrics for the subject #1 ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #1 equal: DICE1=[ 0.8652 0.3116 0.4263 0.0000 0.6456 ] DICE2=[ 0.8656 0.3122 0.4263 0.0000 0.6458 ] DICE3=[ 0.8656 0.3122 0.4264 0.0000 0.6458 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "+++++++++++++++++++++++++++++++ Segmentation of all subjects finished +++++++++++++++++++++++++++++++++++\n",
            "+++++++++++++++++++++ Reporting Average Segmentation Metrics over all subjects ++++++++++++++++++++++++++\n",
            "ACCURACY: (Validation) The Per-Class average DICE Coefficients over all subjects are: DICE1=[ 0.8519 0.1558 0.5995 0.0000 0.5638 ] DICE2=[ 0.8545 0.1561 0.5995 0.0000 0.5640 ] DICE3=[ 0.8547 0.1561 0.5997 0.0000 0.5640 ]\n",
            "EXPLANATION: DICE1/2/3 are lists with the DICE per class. For Class-0, we calculate DICE for whole foreground, i.e all labels merged, except the background label=0. Useful for multi-class problems.\n",
            "EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT). DICE2 is the segmentation within the ROI vs GT. DICE3 is segmentation within the ROI vs the GT within the ROI.\n",
            "EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.\n",
            "TIMING: Validation process lasted: 12.35 secs.\n",
            "###########################################################################################################\n",
            "############################# Finished full Segmentation of Validation subjects ##########################\n",
            "###########################################################################################################\n",
            "TIMING: Training process lasted: 80.3 secs.\n",
            "Closing worker pool.\n",
            "Saving the final model at:/content/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751\n",
            "The whole do_training() function has finished.\n",
            "\n",
            "=======================================================\n",
            "=========== Training session finished =================\n",
            "=======================================================\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kElwOIOC0K--",
        "colab_type": "code",
        "outputId": "3681418c-e20b-4be4-d99f-f92f39fc5d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Checking output folders that should have been created by the training process as explained above.\n",
        "!ls -lrt ./examples/output/saved_models/trainSessionWithValidTiny/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COPYRIGHT.md  documentation  MANIFEST.in\t      setup.cfg\n",
            "deepmedic     examples\t     plotTrainingProgress.py  setup.py\n",
            "deepMedicRun  LICENSE.txt    README.md\n",
            "total 244\n",
            "-rw-r--r-- 1 root root 54148 May 24 17:48 tinyCnn.trainSessionWithValidTiny.initial.2019-05-24.17.48.23.753012.model.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root  3025 May 24 17:48 tinyCnn.trainSessionWithValidTiny.initial.2019-05-24.17.48.23.753012.model.ckpt.index\n",
            "-rw-r--r-- 1 root root  3025 May 24 17:48 tinyCnn.trainSessionWithValidTiny.2019-05-24.17.48.52.165167.model.ckpt.index\n",
            "-rw-r--r-- 1 root root 54148 May 24 17:48 tinyCnn.trainSessionWithValidTiny.2019-05-24.17.48.52.165167.model.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 54148 May 24 17:49 tinyCnn.trainSessionWithValidTiny.2019-05-24.17.49.31.804131.model.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root  3025 May 24 17:49 tinyCnn.trainSessionWithValidTiny.2019-05-24.17.49.31.804131.model.ckpt.index\n",
            "-rw-r--r-- 1 root root 54148 May 24 17:49 tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root  3025 May 24 17:49 tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt.index\n",
            "-rw-r--r-- 1 root root   905 May 24 17:49 checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x94wNoh9_6Tw",
        "colab_type": "text"
      },
      "source": [
        "Finally, the following command will run a test with the trained model, specifying which previously-trained model/checkpoint to load from with the -load option. The path given should not correspond neither to the data nor index file, but needs to refer to the checkpoint set, as Tensorflow's loader peculiarity. Of course, in order for this testing to work, **the corresponding date+time must be updated for the command to load the correct file to test**, which is found as an output of the previous cell.\n",
        "\n",
        "This process performs segmentation of the testing images and the results will appear in examples/output/predictions/testSessionTiny/ in the predictions folder. In the features folder there will be some files with feature maps from the second layer. DeepMedic gives this functionality (testConfig.cfg)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti_SFWLOaIS2",
        "colab_type": "code",
        "outputId": "76ed03b2-6230-4f0a-a995-5134a5190459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4304
        }
      },
      "source": [
        "# Testing to check how the model just trained actually works.\n",
        "!./deepMedicRun -model ./examples/configFiles/tinyCnn/model/modelConfig.cfg -test ./examples/configFiles/tinyCnn/test/testConfig.cfg -load ./examples/output/saved_models/trainSessionWithValidTiny/tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given configuration file:  /content/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg\n",
            "Given configuration file:  /content/deepmedic/examples/configFiles/tinyCnn/test/testConfig.cfg\n",
            "Creating necessary folders for testing session...\n",
            "=============================== logger created =======================================\n",
            "\n",
            "======================== Starting new session ============================\n",
            "Command line arguments given: \n",
            "Namespace(device='cpu', model_cfg='./examples/configFiles/tinyCnn/model/modelConfig.cfg', reset_trainer=False, saved_model='./examples/output/saved_models/trainSessionWithValidTiny/tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt', test_cfg='./examples/configFiles/tinyCnn/test/testConfig.cfg', train_cfg=None)\n",
            "2019-05-24 18:55:51.123050: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-05-24 18:55:51.142757: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-05-24 18:55:51.142812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: 42c889d225a5\n",
            "2019-05-24 18:55:51.142828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: 42c889d225a5\n",
            "2019-05-24 18:55:51.142878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 410.79.0\n",
            "2019-05-24 18:55:51.142916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 410.79.0\n",
            "2019-05-24 18:55:51.142930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 410.79.0\n",
            "2019-05-24 18:55:51.144881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-24 18:55:51.145062: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2bdf080 executing computations on platform Host. Devices:\n",
            "2019-05-24 18:55:51.145092: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "Available devices to Tensorflow:\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11322197174119056779\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 4348391955371131562\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n",
            "CONFIG: The configuration file for the [model] given is: /content/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg\n",
            "=============================================================\n",
            "========== PARAMETERS FOR MAKING THE ARCHITECTURE ===========\n",
            "=============================================================\n",
            "CNN model's name = tinyCnn\n",
            "~~~~~~~~~~~~~~~~~~Model parameters~~~~~~~~~~~~~~~~\n",
            "Number of Classes (including background) = 5\n",
            "~~Normal Pathway~~\n",
            "Number of Input Channels = 2\n",
            "Number of Layers = 3\n",
            "Number of Feature Maps per layer = [4, 5, 6]\n",
            "Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
            "Receptive Field = [7, 7, 7]\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Lower Rank layers will be made of rank = []\n",
            "~~Subsampled Pathway~~\n",
            "Use subsampled Pathway = True\n",
            "Number of subsampled pathways that will be built = 1\n",
            "Number of Layers (per sub-pathway) = [3]\n",
            "Number of Feature Maps per layer (per sub-pathway) = [[4, 5, 6]]\n",
            "Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
            "Receptive Field = [7, 7, 7]\n",
            "Subsampling Factor per dimension (per sub-pathway) = [[3, 3, 3]]\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Lower Rank layers will be made of rank = []\n",
            "~~Fully Connected Pathway~~\n",
            "Number of additional FC layers (Excluding the Classif. Layer) = 0\n",
            "Number of Feature Maps in the additional FC layers = []\n",
            "Residual connections added at the output of layers (indices from 0) = []\n",
            "Layers that will be made of Lower Rank (indices from 0) = []\n",
            "Dimensions of Kernels in the 1st FC layer (Classif. layer if no hidden FCs used) = [1, 1, 1]\n",
            "~~Size Of Image Segments~~\n",
            "Size of Segments for Training = [25, 25, 25]\n",
            "Size of Segments for Validation = [7, 7, 7]\n",
            "Size of Segments for Testing = [45, 45, 45]\n",
            "~~Dropout Rates~~\n",
            "Drop.R. for each layer in Normal Pathway = []\n",
            "Drop.R. for each layer in Subsampled Pathway = []\n",
            "Drop.R. for each layer in FC Pathway (additional FC layers + Classific.Layer at end) = [0.5]\n",
            "~~Weight Initialization~~\n",
            "Initialization method and params for the conv kernel weights = ['fanIn', 2]\n",
            "~~Activation Function~~\n",
            "Activation function to use = prelu\n",
            "~~Batch Normalization~~\n",
            "Apply BN straight on pathways' inputs (eg straight on segments) = [False, False, True]\n",
            "Batch Normalization uses a rolling average for inference, over this many batches = 60\n",
            "========== Done with printing session's parameters ==========\n",
            "=============================================================\n",
            "CONFIG: The configuration file for the [session] was loaded from: /content/deepmedic/examples/configFiles/tinyCnn/test/testConfig.cfg\n",
            "\n",
            "============     NEW TESTING SESSION    ===============\n",
            "\n",
            "=============================================================\n",
            "=========== PARAMETERS OF THIS TESTING SESSION ==============\n",
            "=============================================================\n",
            "sessionName = testSessionTiny\n",
            "Model will be loaded from save = /content/deepmedic/examples/output/saved_models/trainSessionWithValidTiny/tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt\n",
            "~~~~~~~~~~~~~~~~~~~~INPUT~~~~~~~~~~~~~~~~\n",
            "Number of cases to perform inference on = 2\n",
            "Paths to the channels of each case = [['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0001_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0001_1/T1c_subtrMeanDivStd.nii.gz'], ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0002_1/Flair_subtrMeanDivStd.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0002_1/T1c_subtrMeanDivStd.nii.gz']]\n",
            "User provided Ground Truth labels for DSC calculation = False\n",
            ">>> WARN: The DSC accuracy will NOT be evaluated and reported!\n",
            "Paths to the provided GT labels per case = None\n",
            "User provided Region-Of-Interest Masks for faster inference = True\n",
            "Filepaths of the ROI Masks provided per case = ['/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0001_1/brainmask.nii.gz', '/content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0002_1/brainmask.nii.gz']\n",
            "Batch size = 10\n",
            "~~~~~~~~~~~~~~~~~~~OUTPUT~~~~~~~~~~~~~~~\n",
            "Path to the main output-folder = /content/deepmedic/examples/output\n",
            "Provided names to use to save results for each case = ['pred_brats_2013_pat0001_1.nii.gz', 'pred_brats_2013_pat0002_1.nii.gz']\n",
            "~~~~~~~Ouput-parameters for Predictions (segmentation and probability maps)~~~~\n",
            "Save the predicted segmentation = True\n",
            "Save the probability maps = [True, True, True, True, True]\n",
            "Paths where to save predictions per case = ['/content/deepmedic/examples/output/predictions/testSessionTiny/predictions//pred_brats_2013_pat0001_1.nii.gz', '/content/deepmedic/examples/output/predictions/testSessionTiny/predictions//pred_brats_2013_pat0002_1.nii.gz']\n",
            "Suffixes with which to save segmentations and probability maps = {'segm': 'Segm', 'prob': 'ProbMapClass'}\n",
            "~~~~~~~Ouput-parameters for Feature Maps (FMs)~~~~~~\n",
            "Save FMs in individual images = True\n",
            "Save all requested FMs in one 4D image = False\n",
            "Indices of min/max FMs to save, per type of pathway (normal/subsampled/FC) and per layer = [[[], [1, 3], []], [], [[]]]\n",
            "Save Feature Maps at = ['/content/deepmedic/examples/output/predictions/testSessionTiny/features//pred_brats_2013_pat0001_1.nii.gz', '/content/deepmedic/examples/output/predictions/testSessionTiny/features//pred_brats_2013_pat0002_1.nii.gz']\n",
            "~~~~~~~ Parameters for Preprocessing ~~~~~~\n",
            "Pad Input Images = True\n",
            "========== Done with printing session's parameters ==========\n",
            "=============================================================\n",
            "\n",
            "=======================================================\n",
            "\n",
            "=========== Making the CNN graph... ===============\n",
            "...Building the CNN model...\n",
            "[Pathway_NORMAL] is being built...\n",
            "\t[Pathway_NORMAL]: Input's Shape: (Train) [None, 2, 25, 25, 25], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 45, 45, 45]\n",
            "\t[Conv.Layer_0], Filter Shape: [4, 2, 3, 3, 3]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 2, 25, 25, 25], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 45, 45, 45]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\t[Conv.Layer_1], Filter Shape: [5, 4, 3, 3, 3]\n",
            "\t[Conv.Layer_1], Input's Shape: (Train) [None, 4, 23, 23, 23], (Val) [None, 4, 5, 5, 5], (Test) [None, 4, 43, 43, 43]\n",
            "\t[Conv.Layer_2], Filter Shape: [6, 5, 3, 3, 3]\n",
            "\t[Conv.Layer_2], Input's Shape: (Train) [None, 5, 21, 21, 21], (Val) [None, 5, 3, 3, 3], (Test) [None, 5, 41, 41, 41]\n",
            "\t[Pathway_NORMAL]: Output's Shape: (Train) [None, 6, 19, 19, 19], (Val) [None, 6, 1, 1, 1], (Test) [None, 6, 39, 39, 39]\n",
            "[Pathway_NORMAL] done.\n",
            "[Pathway_SUBSAMPLED[3, 3, 3]] is being built...\n",
            "\t[Pathway_SUBSAMPLED[3, 3, 3]]: Input's Shape: (Train) [None, 2, 13, 13, 13], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 19, 19, 19]\n",
            "\t[Conv.Layer_0], Filter Shape: [4, 2, 3, 3, 3]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 2, 13, 13, 13], (Val) [None, 2, 7, 7, 7], (Test) [None, 2, 19, 19, 19]\n",
            "\t[Conv.Layer_1], Filter Shape: [5, 4, 3, 3, 3]\n",
            "\t[Conv.Layer_1], Input's Shape: (Train) [None, 4, 11, 11, 11], (Val) [None, 4, 5, 5, 5], (Test) [None, 4, 17, 17, 17]\n",
            "\t[Conv.Layer_2], Filter Shape: [6, 5, 3, 3, 3]\n",
            "\t[Conv.Layer_2], Input's Shape: (Train) [None, 5, 9, 9, 9], (Val) [None, 5, 3, 3, 3], (Test) [None, 5, 15, 15, 15]\n",
            "\t[Pathway_SUBSAMPLED[3, 3, 3]]: Output's Shape: (Train) [None, 6, 7, 7, 7], (Val) [None, 6, 1, 1, 1], (Test) [None, 6, 13, 13, 13]\n",
            "[Pathway_SUBSAMPLED[3, 3, 3]] done.\n",
            "DEBUG: Shape of the kernel of the first FC layer is : [1, 1, 1]\n",
            "DEBUG: Input to the FC Pathway will be padded by that many voxels per dimension: [0, 0, 0]\n",
            "[Pathway_FC] is being built...\n",
            "\t[Pathway_FC]: Input's Shape: (Train) [None, 12, 19, 19, 19], (Val) [None, 12, 1, 1, 1], (Test) [None, 12, 39, 39, 39]\n",
            "\t[Conv.Layer_0], Filter Shape: [5, 12, 1, 1, 1]\n",
            "\t[Conv.Layer_0], Input's Shape: (Train) [None, 12, 19, 19, 19], (Val) [None, 12, 1, 1, 1], (Test) [None, 12, 39, 39, 39]\n",
            "\t[Pathway_FC]: Output's Shape: (Train) [None, 5, 19, 19, 19], (Val) [None, 5, 1, 1, 1], (Test) [None, 5, 39, 39, 39]\n",
            "[Pathway_FC] done.\n",
            "Adding the final Softmax Target layer...\n",
            "Finished building the CNN's model.\n",
            "=========== Compiling the Testing Function ============\n",
            "=======================================================\n",
            "\n",
            "...Building the function for testing and visualisation of FMs...\n",
            "...Collecting ops and feeds for testing...\n",
            "Done.\n",
            "=========== Loading parameters from specified saved model ===============\n",
            "Loading parameters from:/content/deepmedic/examples/output/saved_models/trainSessionWithValidTiny/tinyCnn.trainSessionWithValidTiny.final.2019-05-24.17.49.44.218751.model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Parameters were loaded.\n",
            "\n",
            "======================================================\n",
            "=========== Testing with the CNN model ===============\n",
            "======================================================\n",
            "\n",
            "###########################################################################################################\n",
            "############################# Starting full Segmentation of Testing subjects ##########################\n",
            "###########################################################################################################\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #0 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0001_1/Flair_subtrMeanDivStd.nii.gz\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:90\n",
            "Processed 10/90 segments.\n",
            "Processed 20/90 segments.\n",
            "Processed 30/90 segments.\n",
            "Processed 40/90 segments.\n",
            "Processed 50/90 segments.\n",
            "Processed 60/90 segments.\n",
            "Processed 70/90 segments.\n",
            "Processed 80/90 segments.\n",
            "Processed 90/90 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.08 [ForwardPass:] 25.56 [Total:] 25.66 secs.\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #0\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0001_1_ProbMapClass4.nii.gz\n",
            "Saving the new FM-activation image for the subject #0, pathway:0, layer: 1 FM: 1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/features/pred_brats_2013_pat0001_1_pathway0_layer1_fm1.nii.gz\n",
            "Saving the new FM-activation image for the subject #0, pathway:0, layer: 1 FM: 2\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/features/pred_brats_2013_pat0001_1_pathway0_layer1_fm2.nii.gz\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~ Segmenting subject with index #1 ~~~~~~~~~~~~~~~~~~~~\n",
            "Loading subject with 1st channel at: /content/deepmedic/examples/dataForExamples/brats2015TrainingData/test/brats_2013_pat0002_1/Flair_subtrMeanDivStd.nii.gz\n",
            "Starting to (tile) extract Segments from the images of the subject for Segmentation...\n",
            "Finished (tiling) extracting Segments from the images of the subject for Segmentation.\n",
            "Starting to segment each image-part by calling the cnn.cnnTestModel(i). This part takes a few mins per volume...\n",
            "Total number of Segments to process:90\n",
            "Processed 10/90 segments.\n",
            "Processed 20/90 segments.\n",
            "Processed 30/90 segments.\n",
            "Processed 40/90 segments.\n",
            "Processed 50/90 segments.\n",
            "Processed 60/90 segments.\n",
            "Processed 70/90 segments.\n",
            "Processed 80/90 segments.\n",
            "Processed 90/90 segments.\n",
            "TIMING: Segmentation of subject: [Extracting:] 0.02 [Loading:] 0.09 [ForwardPass:] 23.31 [Total:] 23.41 secs.\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_Segm.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_ProbMapClass0.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_ProbMapClass1.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_ProbMapClass2.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_ProbMapClass3.nii.gz\n",
            "Saving the new label (segmentation) image for the subject #1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/predictions/pred_brats_2013_pat0002_1_ProbMapClass4.nii.gz\n",
            "Saving the new FM-activation image for the subject #1, pathway:0, layer: 1 FM: 1\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/features/pred_brats_2013_pat0002_1_pathway0_layer1_fm1.nii.gz\n",
            "Saving the new FM-activation image for the subject #1, pathway:0, layer: 1 FM: 2\n",
            "Image saved at: /content/deepmedic/examples/output/predictions/testSessionTiny/features/pred_brats_2013_pat0002_1_pathway0_layer1_fm2.nii.gz\n",
            "TIMING: Testing process lasted: 60.58 secs.\n",
            "###########################################################################################################\n",
            "############################# Finished full Segmentation of Testing subjects ##########################\n",
            "###########################################################################################################\n",
            "\n",
            "======================================================\n",
            "=========== Testing session finished =================\n",
            "======================================================\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMGyswxO9WJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5c2933a0-e022-40fd-a52d-47144a13d824"
      },
      "source": [
        "# Checking output folders that should have been created by the testing process as explained above.\n",
        "!ls -lrt ./examples/output/predictions/testSessionTiny/*"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./examples/output/predictions/testSessionTiny/predictions:\n",
            "total 56868\n",
            "-rw-r--r-- 1 root root  149831 May 24 18:56 pred_brats_2013_pat0001_1_Segm.nii.gz\n",
            "-rw-r--r-- 1 root root 5510210 May 24 18:56 pred_brats_2013_pat0001_1_ProbMapClass0.nii.gz\n",
            "-rw-r--r-- 1 root root 5716053 May 24 18:56 pred_brats_2013_pat0001_1_ProbMapClass1.nii.gz\n",
            "-rw-r--r-- 1 root root 5642884 May 24 18:56 pred_brats_2013_pat0001_1_ProbMapClass2.nii.gz\n",
            "-rw-r--r-- 1 root root 5660845 May 24 18:56 pred_brats_2013_pat0001_1_ProbMapClass3.nii.gz\n",
            "-rw-r--r-- 1 root root 5637749 May 24 18:56 pred_brats_2013_pat0001_1_ProbMapClass4.nii.gz\n",
            "-rw-r--r-- 1 root root  130974 May 24 18:56 pred_brats_2013_pat0002_1_Segm.nii.gz\n",
            "-rw-r--r-- 1 root root 5823443 May 24 18:56 pred_brats_2013_pat0002_1_ProbMapClass0.nii.gz\n",
            "-rw-r--r-- 1 root root 6061047 May 24 18:56 pred_brats_2013_pat0002_1_ProbMapClass1.nii.gz\n",
            "-rw-r--r-- 1 root root 5950986 May 24 18:56 pred_brats_2013_pat0002_1_ProbMapClass2.nii.gz\n",
            "-rw-r--r-- 1 root root 5967841 May 24 18:56 pred_brats_2013_pat0002_1_ProbMapClass3.nii.gz\n",
            "-rw-r--r-- 1 root root 5960588 May 24 18:56 pred_brats_2013_pat0002_1_ProbMapClass4.nii.gz\n",
            "\n",
            "./examples/output/predictions/testSessionTiny/features:\n",
            "total 27132\n",
            "-rw-r--r-- 1 root root 6639431 May 24 18:56 pred_brats_2013_pat0001_1_pathway0_layer1_fm1.nii.gz\n",
            "-rw-r--r-- 1 root root 6768033 May 24 18:56 pred_brats_2013_pat0001_1_pathway0_layer1_fm2.nii.gz\n",
            "-rw-r--r-- 1 root root 7101208 May 24 18:56 pred_brats_2013_pat0002_1_pathway0_layer1_fm1.nii.gz\n",
            "-rw-r--r-- 1 root root 7267442 May 24 18:56 pred_brats_2013_pat0002_1_pathway0_layer1_fm2.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
